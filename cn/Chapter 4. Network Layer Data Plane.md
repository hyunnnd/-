
## 📌 Network-layer services and protocols (네트워크 계층 서비스 및 프로토콜)

### 1. 송신 호스트에서 수신 호스트로 세그먼트 전달

- **송신자(sender)**  
    전송 계층에서 만들어진 세그먼트를 **데이터그램(datagram)** 형태로 캡슐화한 뒤 **링크 계층으로 전달**합니다.

- **수신자(receiver)**  
    링크 계층으로부터 수신한 데이터그램에서 세그먼트를 **추출하여 전송 계층 프로토콜에 전달**합니다.    

### 2. 네트워크 계층 프로토콜의 적용 범위

- 네트워크 계층은 **모든 인터넷 장치(every Internet device)** 에 존재합니다.  
    예시: **호스트(host), 라우터(router)**

### 3. 라우터의 역할

- **수신한 모든 IP 데이터그램의 헤더 필드를 검사**합니다.
- **입력 포트에서 받은 데이터그램을 적절한 출력 포트로 전달**하여  
    **종단 간(end-to-end) 경로를 따라 데이터그램이 이동하도록 함**.

## 📌 그림 설명 (간단 해설)

- 모바일 네트워크, 기업 네트워크, 데이터센터 네트워크, 글로벌 ISP 등이 **연결되어 하나의 인터넷 경로를 구성**하고 있습니다.
- 각 라우터는 **network / link / physical 계층**으로 구성되어 있으며  
    패킷을 전달할 때 **상위 계층의 데이터를 해석하지 않고 IP 헤더만 기반으로 전달 결정**을 수행합니다.
- **호스트는 application / transport / network / link / physical 계층을 모두 사용**합니다.

## 💡 핵심 요약

| 구성 요소      | 역할                                |
| ---------- | --------------------------------- |
| Sender     | 세그먼트를 데이터그램으로 캡슐화 후 링크 계층으로 전달    |
| Receiver   | 데이터그램에서 세그먼트를 추출해 전송 계층으로 전달      |
| Router     | IP 헤더 검사, 입력 포트 → 출력 포트로 데이터그램 전달 |
| Network 계층 | 모든 인터넷 장치에 존재하며 IP 기반 전달 수행       |

## ✔ 보충 설명

- 네트워크 계층의 대표 프로토콜은 **IP(Internet Protocol)** 입니다.    
- 라우터는 **IP 주소 기반으로 경로를 결정(route)** 하며, **종단 간 신뢰성 보장은 하지 않습니다**.  
    신뢰성은 전송 계층(TCP 등)이 담당합니다.
- 데이터그램 전달의 목표는 **최선형(best-effort)** 전달이며,  
    **지연·손실이 발생하더라도 재전송을 보장하지 않습니다**.



## 📌 Two key network-layer functions (네트워크 계층의 두 핵심 기능)

### 1) Forwarding (포워딩)

- 라우터의 **입력 링크로 들어온 패킷을 적절한 출력 링크로 이동시키는 과정**입니다.
- 즉, **패킷을 다음 라우터 또는 목적지로 넘기는 동작 자체**를 의미합니다.

### 2) Routing (라우팅)

- 패킷이 **출발지에서 목적지까지 도달하기 위한 전체 경로를 결정하는 과정**입니다.
- **라우팅 알고리즘(routing algorithms)** 을 사용하여 최적 경로를 계산합니다.    

## 🔍 둘의 차이를 이해하는 비유 (여행에 비교)

|개념|여행에 비유|설명|
|---|---|---|
|Forwarding|교차로(인터체인지)에서 길을 선택해 빠져나오는 과정|이미 계획된 경로에 따라 다음 구간으로 이동하는 수행 단계|
|Routing|출발지부터 목적지까지 갈 전체 경로를 사전에 계획하는 과정|어떤 경로로 갈지 결정하는 계획 단계|

## ✔ 핵심 요약

|항목|수행 시점|담당 주체|주요 작동 방식|
|---|---|---|---|
|Forwarding|실시간 패킷 전달 중|라우터|포워딩 테이블을 기반으로 다음 출력 포트 선택|
|Routing|경로 계산 단계|각각의 라우터 + 네트워크 전체|라우팅 알고리즘을 통해 경로 계산 후 라우팅 테이블 구성|


## 💡 추가 설명

- Forwarding과 Routing은 함께 동작하지만 **책임 범위가 다릅니다**.  
    Forwarding은 **“지금 이 패킷을 어디로 보낼까?”**,  
    Routing은 **“전체적으로 어떤 경로가 가장 최적·가장 빠르게 목적지에 도달할까?”** 를 결정합니다.
- Routing의 결과가 **라우팅 테이블을 생성하고 유지**, Forwarding은 **라우팅 테이블을 실제 패킷 전달에 사용**합니다.


## 📌 Network layer: data plane, control plane (네트워크 계층: 데이터 플레인, 컨트롤 플레인)

### 🔹 Data Plane (데이터 플레인)

- **로컬(local), 라우터별 기능**
- 라우터의 **입력 포트로 들어온 데이터그램을 어떤 출력 포트로 전달할지 결정하는 역할**
- 즉, **포워딩(forwarding)** 기능을 수행하는 영역입니다.

> 도착한 패킷 헤더의 값을 기반으로 → 포워딩 테이블을 조회 → 특정 출력 포트로 패킷을 전송

### 🔹 Control Plane (컨트롤 플레인)

- **네트워크 전체 관점(network-wide logic)**    
- 데이터그램이 **출발지에서 목적지까지 네트워크 내 여러 라우터를 어떤 경로로 통과할지 결정**
- 즉, **라우팅(routing)** 기능을 수행하는 영역입니다.

#### 컨트롤 플레인의 두 가지 방식

| 방식                  | 설명                   | 구현 위치     |
| ------------------- | -------------------- | --------- |
| 전통적 라우팅 알고리즘        | 각 라우터가 스스로 라우팅 계산 수행 | 라우터 내부    |
| 소프트웨어 정의 네트워킹 (SDN) | 컨트롤 기능을 서버에 중앙집중화    | 외부(원격) 서버 |

## ✔ 핵심 비교 요약

| 항목    | Data Plane            | Control Plane            |
| ----- | --------------------- | ------------------------ |
| 기능    | 패킷 전달 (포워딩)           | 경로 결정 (라우팅)              |
| 적용 범위 | 개별 라우터 로컬             | 네트워크 전체                  |
| 작동 방식 | 포워딩 테이블 기반으로 출력 포트 선택 | 라우팅 알고리즘 또는 SDN 기반 경로 계산 |
| 시간 특성 | 실시간                   | 비실시간 (계산 후 테이블에 반영)      |

## 💡 추가 설명

- Control Plane이 **라우팅 테이블을 생성·관리**하고, Data Plane은 그 테이블을 기반으로 **실제로 패킷을 전달**합니다.    
- SDN 방식에서는 **제어 기능이 분리되어 중앙 컨트롤러가 경로를 결정**하고, 라우터는 **데이터 전달에만 집중**합니다.
- 이 분리는 대규모 네트워크에서 **트래픽 관리 효율성, 정책 적용, 네트워크 확장성**을 향상시킵니다.


## 📌 Per-router control plane (라우터별 컨트롤 플레인)

### 🔹 개념 설명

- **각 라우터 내부에 라우팅 알고리즘이 존재하며**,  
    이 라우팅 알고리즘들이 서로 **정보를 교환하며 컨트롤 플레인을 구성**합니다.
- 즉, **네트워크 전체 경로를 계산하는 작업을 각 라우터가 분산적으로 수행**하는 방식입니다.

### 🔹 동작 과정 이해

1. 각 라우터는 **라우팅 알고리즘을 실행**합니다.    
2. 라우터끼리는 **라우팅 정보를 서로 교환**합니다. (그림의 빨간 화살표)
3. 이 정보 교환을 통해 **라우팅 테이블이 업데이트**됩니다.
4. 업데이트된 테이블이 **데이터 플레인에 반영**되어 포워딩이 수행됩니다.

### 🔹 구조적 분리

| 영역            | 역할                     | 위치         |
| ------------- | ---------------------- | ---------- |
| Control Plane | 라우팅 계산 및 테이블 생성        | 라우터 내부(상단) |
| Data Plane    | 라우팅 테이블을 바탕으로 실제 패킷 전달 | 라우터 내부(하단) |

### 🔹 그림의 핵심 포인트 요약

- **좌측 패킷 예시**  
    패킷의 헤더 값이 입력되면 → **로컬 포워딩 테이블 조회 → 출력 포트 선택**    
- **각 라우터 상단의 빨간 연결선**  
    라우터들 간 **라우팅 정보 교환 → 컨트롤 플레인 형성**
- **각 라우터 하단의 파란 부분**  
    실제 패킷 전달이 이루어지는 **데이터 플레인**

## ✔ 핵심 요약

| 특징        | Per-router control plane        |
| --------- | ------------------------------- |
| 라우팅 계산 방식 | 라우터 개별적으로 수행 (분산형)              |
| 장점        | 장애 시에도 일부 라우터는 계속 동작 가능, 분산적 확장 |
| 단점        | 관리 어려움, 라우팅 계산 복잡 및 비효율 가능      |
| 대표 기술     | RIP, OSPF, BGP 등 기존 라우팅 프로토콜    |


## 📌 Software-Defined Networking (SDN) control plane

**SDN 컨트롤 플레인**

### 🔹 핵심 개념

- **컨트롤 플레인 기능을 라우터 내부가 아닌 외부(원격) 컨트롤러에 집중시키는 방식**입니다.
- 원격 컨트롤러가 **라우팅 계산을 수행하고**, 그 결과를 라우터에 전달하여 **포워딩 테이블을 설치**합니다.

### 🔹 동작 과정 요약

1. 네트워크 전체의 상태를 SDN 컨트롤러가 수집합니다.    
2. 컨트롤러가 **패킷 경로(라우팅)** 를 통합적으로 계산합니다.
3. 계산된 결과를 각 라우터에 전달하여 **포워딩 테이블을 구성/업데이트**합니다.
4. 라우터는 전달받은 포워딩 테이블을 사용하여 **데이터 플레인에서 실시간 패킷 전달**을 수행합니다.

> 즉, **라우팅 결정은 중앙 서버가 담당하고**, **라우터는 전달(Forwarding) 기능에만 집중합니다.**

### 🔹 구조적 분리

| 영역            | 역할               | 위치              |
| ------------- | ---------------- | --------------- |
| Control Plane | 라우팅 계산 및 정책 적용   | SDN 원격 컨트롤러(중앙) |
| Data Plane    | 포워딩 테이블 기반 패킷 전달 | 개별 라우터 내부       |


### 🔹 그림 이해 포인트

- 상단의 **Remote Controller**  
    → 네트워크 전체 경로를 계획하여 포워딩 테이블을 생성    
- 하단의 **라우터들 (CA 표기)**  
    → 컨트롤러가 내려주는 테이블을 수신하고 데이터 전달만 수행
- 빨간 화살표  
    → 컨트롤러 ↔ 라우터 간 포워딩 규칙 전달

## ✔ SDN의 장점

| 항목        | 설명                             |
| --------- | ------------------------------ |
| 중앙 집중 관리  | 네트워크 전체 정책 및 경로를 컨트롤러에서 일괄 제어  |
| 유연성 및 확장성 | 소프트웨어 업데이트만으로 네트워크 동작 변경 가능    |
| 자동화       | 트래픽 상황에 따라 실시간 라우팅 정책 자동 조정 가능 |

## ✔ SDN의 단점

| 항목           | 설명                                   |
| ------------ | ------------------------------------ |
| 컨트롤러 장애 시 위험 | 단일 장애 지점(Single Point of Failure) 가능 |
| 높은 초기 구축 비용  | 컨트롤러 인프라 구축 및 장비 호환 필요               |

## 💡 Per-router Control Plane과의 비교

| 방식           | Per-router control plane | SDN control plane            |
| ------------ | ------------------------ | ---------------------------- |
| 구조           | 분산형                      | 중앙집중형                        |
| 라우팅 계산 수행 주체 | 각 라우터                    | SDN 컨트롤러                     |
| 라우터의 역할      | 경로 계산 + 전달               | 전달(Forwarding) 전담            |
| 대표 프로토콜/기술   | RIP, OSPF, BGP           | OpenFlow, ONOS, OpenDaylight |


## 📌 Network service model (네트워크 서비스 모델)

### 🔹 핵심 질문

> 송신자에서 수신자로 데이터그램을 운반하는 **채널이 제공할 수 있는 서비스 모델은 무엇인가?**

네트워크 계층은 모든 데이터그램을 그냥 “최선형 전달(best-effort)”로 보내는 것만이 아니라, 특정 서비스 품질(QoS)을 제공하도록 설계될 수도 있습니다.

## 🔸 서비스 모델의 예시

### 1) 개별 데이터그램을 위한 서비스 (individual datagrams)

|서비스 예시|설명|
|---|---|
|guaranteed delivery|데이터그램의 **전달을 보장**|
|guaranteed delivery with less than 40 ms delay|**40ms 이하의 지연을 보장하면서 전달**|

→ 단일 패킷의 도착 여부 및 지연 시간에 초점을 둔 서비스

### 2) 데이터그램 흐름(flow) 전체를 위한 서비스

한 세션 또는 스트림 단위의 패킷 흐름(flow)에 대해 적용되는 서비스

|서비스 예시|설명|
|---|---|
|in-order datagram delivery|패킷을 **전송한 순서대로 도착하도록 보장**|
|guaranteed minimum bandwidth to flow|해당 흐름을 위해 **최소 대역폭을 보장**|
|restrictions on changes in inter-packet spacing|**패킷 간 시간 간격(inter-packet spacing)의 변화를 제한**하여 지터(jitter) 억제|

→ 실시간 스트리밍, 화상회의, 온라인 게임 등 연속적인 패킷 품질이 중요한 서비스에서 필요

## 💡 정리 요약

|서비스 범위|초점|예시|
|---|---|---|
|개별 데이터그램|하나의 패킷의 안전성과 지연|guaranteed delivery, low-delay delivery|
|데이터그램 흐름|스트림 전체의 품질과 일관성|in-order delivery, bandwidth guarantee, jitter control|


## 📌 Network-layer service model (네트워크 계층 서비스 모델)

### 🔹 현재 인터넷의 네트워크 서비스 모델

|Network Architecture|Service Model|QoS 보장 항목|
|---|---|---|
|Internet|best effort|Bandwidth: none / Loss: no / Order: no / Timing: no|

인터넷은 **best effort** 방식을 사용하며, 이는 **전송 품질을 보장하지 않는 모델**을 의미합니다.

### 🔹 Best-effort 서비스 모델의 특징

**보장하지 않는 항목**

1. **데이터그램이 목적지까지 성공적으로 전달된다는 보장 없음**
2. **도착 시간(timing) 또는 순서(order)에 대한 보장 없음**
3. **종단 간(end-to-end) 흐름에 대해 사용 가능한 대역폭 보장 없음**

즉, 네트워크 계층은 패킷을 “가능한 한 전달해 보려는 노력”만 수행하며,  
**지연, 손실, 재전송, 순서 유지, 대역폭 확보 등에 대한 책임을 지지 않습니다.**

### 💡 추가 설명

- TCP, UDP 등의 전송 계층이 **신뢰성 보완 역할을 담당하는 이유**가 바로 이 best-effort 모델 때문입니다.
    - TCP는 손실 복구, 순서 재정렬, 흐름 제어 등을 제공
    - UDP는 보장을 하지 않고 지연을 최소화하는 방향 선택

- 네트워크 계층 자체는 **QoS 지원이 없지만**, 멀티미디어·스트리밍 시대 이후  
    **DiffServ, IntServ, MPLS 등 QoS 기술이 별도로 연구 및 적용**되고 있습니다.    

### ✔ 핵심 요약

|항목|Best-effort 네트워크의 동작 방식|
|---|---|
|패킷 손실|허용됨 (보장하지 않음)|
|전달 순서|보장하지 않음|
|지연 시간|보장하지 않음|
|대역폭|보장하지 않음|
|역할|가능한 한 전달하려고 시도함|


## 📌 Reflections on best-effort service (베스트 에포트 서비스에 대한 고찰)

### 🔹 Best-effort 모델이 성공한 이유

- **메커니즘의 단순성(simplicity of mechanism)**  
    인터넷이 전 세계적으로 빠르게 확산되고 채택될 수 있었던 핵심 요인입니다.  
    설계가 단순하여 확장성·구현 용이성이 매우 뛰어납니다.

- **충분한 대역폭 확보(provisioning of bandwidth)**  
    네트워크 인프라가 발전하면서  
    음성·영상 등 실시간 애플리케이션도 대부분의 시간 동안 충분히 “잘 동작”할 수 있게 되었습니다.
   
- **애플리케이션 계층의 분산 서비스 구조(replication, application-layer distributed services)**  
    데이터센터와 CDN(Content Distribution Network)을  
    사용자 근처에 배치함으로써 가져올 수 있는 성능 향상 덕분에  
    네트워크 계층 QoS 보장이 없어도 서비스 품질을 높일 수 있었습니다.
 
- **탄력적(elastic) 서비스의 혼잡 제어(congestion control)**  
    TCP 기반 서비스와 같은 탄력적 애플리케이션이 혼잡 제어를 수행함으로써  
    네트워크의 과부하 및 붕괴를 방지하고 신뢰성을 높였습니다.
   

### 🔻 결론 문장

> **“best-effort 서비스 모델의 성공을 부정하기는 어렵다.”**  
> → QoS 보장을 제공하지 않지만, 단순성과 확장성, 애플리케이션 계층 기술의 발전으로 인해  
> 인터넷은 오늘날까지도 best-effort 기반으로 안정적으로 유지되고 있습니다.

## 💡 추가 요약 (시험 대비)

| 항목            | 요점                             |
| ------------- | ------------------------------ |
| 핵심 장점         | 단순성, 확장성, 빠른 보급                |
| 어떻게 품질을 보완했는가 | 대역폭 확충, CDN/데이터센터 분산, TCP 혼잡제어 |
| 핵심 메시지        | QoS 없이도 충분히 성공적이었음             |



## 📌 Router architecture overview (라우터 아키텍처 개요)

### 🔹 라우터의 고수준 구조

라우터는 크게 다음 세 부분으로 구성됩니다.

|구성 요소|역할|
|---|---|
|입력 포트 (router input ports)|데이터그램 수신, 헤더 검사, 포워딩 테이블 조회 준비|
|스위칭 패브릭 (high-speed switching fabric)|입력 포트에서 출력 포트로 패킷을 고속으로 전달|
|출력 포트 (router output ports)|큐잉, 스케줄링, 패킷 전송|

### 🔹 Control Plane vs Data Plane

|Plane|역할|위치|동작 속도|
|---|---|---|---|
|Control Plane|라우팅 및 관리 소프트웨어 실행|Routing Processor|밀리초(ms) 시간 단위|
|Data Plane|실제 패킷 포워딩 수행|입·출력 포트 하드웨어|나노초(ns) 시간 단위|

### ✔ Routing Processor (라우팅 프로세서)

- 라우팅 알고리즘, 라우팅 테이블 유지·관리, 네트워크 관리 기능 수행
- 새로운 경로가 학습되면 포워딩 테이블을 업데이트하여 데이터 플레인에 반영

### ✔ High-speed Switching Fabric (고속 스위칭 패브릭)

- 입력 포트에서 출력 포트로 **패킷을 고속으로 연결해 전달**
- 라우터 성능을 좌우하는 핵심 하드웨어


### 🔍 구조를 한 줄로 이해하면

> Control Plane이 **경로를 결정하고**, Data Plane이 **그 경로에 따라 매우 빠르게 패킷을 전달**함

## 핵심 요약

|항목|요점|
|---|---|
|Control Plane|라우팅 계산 및 관리 수행, 느리지만 두뇌 역할|
|Data Plane|패킷 포워딩 처리, 매우 빠른 하드웨어 동작|
|스위칭 패브릭|입력 포트 → 출력 포트 연결|
|시간 단위|Control Plane: ms / Data Plane: ns|

## 📌 Input port functions (입력 포트 기능)

### 🔹 입력 포트 내부 구성 요소

입력 포트는 스위칭 패브릭으로 패킷을 전달하기 전에 다음 단계를 수행합니다.

|단계|설명|관련 계층|
|---|---|---|
|line termination|비트 단위로 신호 수신|물리 계층 (physical layer)|
|link layer protocol (receive)|링크 계층 프레임 처리 (예: Ethernet)|링크 계층 (link layer)|
|lookup, forwarding, queueing|헤더 기반 출력 포트 조회, 큐에 적재 후 전송|네트워크 계층 데이터 플레인|


### 🔹 Decentralized switching (분산 스위칭)

- 입력 포트가 **포워딩 테이블을 자체적으로 보유**하고 있어  
    **헤더 값 기반으로 적절한 출력 포트를 즉시 조회**합니다.
- 즉, **각 입력 포트가 독립적으로 lookup + action 수행**합니다.
- 이 설계의 목적은:
    > 입력 포트에서의 처리 속도를 **line speed(회선 속도)** 에 맞출 수 있도록 하기 위함입니다.

### 🔹 Input port queueing (입력 포트 큐잉)

- 데이터그램 도착 속도가 스위칭 패브릭의 처리 속도보다 빠를 경우  
    입력 포트 내부 큐에 패킷을 저장합니다.    
- 큐가 과도하게 증가할 경우 **패킷 지연 또는 드롭**이 발생할 수 있습니다.

## ✔ 핵심 요약

| 핵심 개념    | 설명                                        |
| -------- | ----------------------------------------- |
| 입력 포트 역할 | 패킷을 수신, 링크 계층 처리, 헤더 기반 출력 포트 조회, 큐잉 수행   |
| 분산 스위칭   | 입력 포트가 자체적으로 lookup 수행 (“match + action”) |
| 목표       | 전체 처리 속도를 line speed로 유지                  |
| 큐잉 이유    | 패킷 도착 속도가 스위칭 패브릭 처리 속도를 초과할 때            |

### 🔹 Destination-based forwarding (목적지 기반 포워딩)

- **목적지 IP 주소만**을 이용하여 포워딩 결정을 수행하는 방식입니다.
- 현재 인터넷에서 사용되는 **전통적·표준적인 포워딩 방식**입니다.
### 🔹 Generalized forwarding (일반화된 포워딩)

- **헤더의 다양한 필드 값 조합**을 기반으로 포워딩 결정을 수행하는 방식입니다.

## 📌 Destination-based forwarding (목적지 기반 포워딩)

### 🔹 Forwarding table 개념

라우터는 **도착지 IP 주소의 비트 패턴 범위**에 따라 **출력 포트를 선택**합니다.

`Destination Address Range  →  Link Interface`

→ 즉, 특정 IP 주소가 어느 범위에 속하는지 확인하여, 해당 범위에 매핑된 인터페이스로 포워딩합니다.

## 📌 예시 ① (정확히 나누어지는 주소 범위)

슬라이드 1은 목적지 주소 범위가 **깔끔하게 연속된 구간으로 분할**되는 경우입니다.

|Destination Address Range|Link Interface|
|---|---|
|11001000 00010111 00010000 00000000 ~ 11001000 00010111 00010111 11111111|0|
|11001000 00010111 00011000 00000000 ~ 11001000 00010111 00011000 11111111|1|
|11001000 00010111 00010001 00000000 ~ 11001000 00010111 00011111 11111111|2|
|Otherwise|3|

→ 목적지 주소가 어떤 범위에 속하는지 확인 → 해당 범위의 인터페이스로 전달

## 📌 예시 ② (범위가 깔끔하게 안 나누어지는 경우)

슬라이드 2는 **주소 범위가 규칙적으로 나누어지지 않을 때**의 forwarding table 예시입니다.

중간 두 항목에 분홍색으로 표시된 부분이  
`00000 100` ~ `00000 111` 처럼 **애매하게 끊기는 작은 주소 구간**을 의미합니다.

이처럼 목적지 범위가 규칙적이지 않은 경우,

- 더 많은 엔트리가 필요해지고
- 테이블 크기는 증가하며
- 검색 비용도 증가합니다.
   
## ❗ 중요한 질문

> 주소 범위가 깔끔하게 나누어지지 않으면 어떻게 되는가?
➡ Forwarding table이 매우 커지고 비효율적이 됩니다.

## 💡 이 문제를 해결하기 위해 등장한 기술

범위 기반 forwarding 테이블의 비효율을 줄이기 위해  
**Longest Prefix Matching (LPM, 최장 접두사 매칭)** 기법이 도입되었습니다.

> 주소 범위를 나열하는 대신 → **공통 접두사(prefix)** 를 사용하여 테이블 엔트리를 최소화

예:

`11001000 00010111 0001xxxx xxxxxxxx  →  output interface #1`

→ CIDR 방식의 IP 주소 체계와 현재 인터넷 라우팅 방식의 기본 원리

## ✔ 핵심 요약

| 항목                           | 내용                                    |
| ---------------------------- | ------------------------------------- |
| Destination-based forwarding | 도착지 주소 기반으로 출력 포트 결정                  |
| 단순한 경우                       | 주소 범위가 깔끔하게 나뉘어 forwarding table이 효율적 |
| 복잡한 경우                       | 엔트리가 비대해지고 검색이 비효율적                   |
| 근본 해결책                       | **Longest Prefix Matching (CIDR 기반)** |


## 📌 Longest Prefix Matching (최장 접두사 매칭)

### 🔹 개념 정의

라우터가 목적지 IP 주소를 기반으로 포워딩 테이블을 조회할 때,  
**가장 길게 일치하는(prefix 길이가 가장 긴) 주소 접두사 항목을 선택하여** 출력 포트를 결정하는 방법입니다.

> 단순히 “처음으로 일치하는 항목”을 선택하는 것이 아니라,  
> **가장 많은 비트가 연속적으로 일치하는 항목을 선택**합니다.

### 🔹 동작 방식 예시 (슬라이드 테이블)

|Destination Address Prefix|Link Interface|
|---|---|
|11001000 00010111 000010*** ********|0|
|11001000 00010111 000011000 ********|1|
|11001000 00010111 000011*** ********|2|
|otherwise|3|

### 🔸 핵심 포인트

- 목적지 주소가 여러 항목과 매칭될 수 있음
- 이 경우 **일치 길이가 가장 긴(prefix가 가장 구체적인) 항목이 선택됨**
- 따라서 테이블 설계 시 **보다 구체적인 주소가 상단에 있을 필요는 없음**  
    → longest prefix rule이 자동으로 선택해 주기 때문입니다.

## 🔍 예시 분석

| 목적지 주소                               | 어떤 인터페이스로 포워딩되는가? |
| ------------------------------------ | ----------------- |
| 11001000 00010111 000010110 10100001 | ?                 |
| 11001000 00010111 000011000 10101010 | ?                 |

### 분석 방법

각 주소의 앞부분을 테이블의 prefix와 비교 →  
가장 긴 bit-prefix가 일치하는 항목을 선택

### 🔺 첫 번째 주소

`11001000 00010111 000010110 10100001`

- 첫 번째 prefix: `11001000 00010111 000010***` ⬅ **일치**    
- 두 번째 prefix: `11001000 00010111 000011000` ⬅ 일부만 일치 (0/1 전환에서 불일치)
- 세 번째 prefix: `11001000 00010111 000011***` ⬅ 일부만 일치

➡ 가장 긴 일치(prefix 길이가 가장 긴 항목) = **첫 번째 항목 → 인터페이스 0**

## 🔺 두 번째 주소

`11001000 00010111 000011000 10101010`

- 두 번째 prefix: `11001000 00010111 000011000` ⬅ **완전히 일치**   
- 세 번째 prefix: `11001000 00010111 000011***` ⬅ 일치하지만 접두사 길이가 더 짧음
- 첫 번째 prefix: 앞부분이 일치하지 않음

➡ 가장 긴 일치(prefix 길이가 가장 긴 항목) = **두 번째 항목 → 인터페이스 1**

## ✔ 최종 요약

| 목적지 주소                               | 선택된 인터페이스       |
| ------------------------------------ | --------------- |
| 11001000 00010111 000010110 10100001 | **Interface 0** |
| 11001000 00010111 000011000 10101010 | **Interface 1** |

## 💡 결론

Longest Prefix Matching의 목적은 다음과 같습니다.

- forwarding table을 **작게** 유지하면서도    
- 다양한 목적지 범위를 **정확하게 구분**하고
- 가장 **특화된(구체적인) 경로를 선택**하도록 보장

따라서 오늘날 인터넷 라우터는 모두 **Longest Prefix Matching + CIDR 주소 체계**를 기반으로 동작합니다.


## 📌 Longest prefix matching — 번역

- 주소 지정(addressing)을 공부할 때, 왜 longest prefix matching이 사용되는지 곧 보게 될 것입니다.
- longest prefix matching은 보통 **삼진 내용 주소 지정 메모리(TCAM, Ternary Content Addressable Memories)** 를 이용하여 수행됩니다.
    - **content addressable**: 주소를 TCAM에 제시하면, 테이블의 크기와 무관하게 **한 클록 사이클 내에** 해당 주소를 검색합니다.
    - Cisco Catalyst: TCAM 안에 약 **100만 개(1M) 라우팅 테이블 엔트리** 저장 가능


## 📌 Switching fabrics — 번역

- 입력 링크에서 적절한 출력 링크로 패킷을 전달한다.
- **switching rate**: 패킷이 입력에서 출력으로 전송될 수 있는 속도
    - 입력/출력 회선 속도의 배수로 측정되는 경우가 많다.
    - N개의 입력이 있을 때, 스위칭 속도가 회선 속도의 **N배가 되는 것이 바람직하다.**

그림 설명:

- 왼쪽에는 **N개의 입력 포트**, 오른쪽에는 **N개의 출력 포트**가 존재하며,  
    가운데의 **고속 스위칭 패브릭**이 입력 포트에서 출력 포트로 패킷을 전달한다.
- 이상적으로는 스위칭 속도가 **NR (회선 속도 × N)** 이 되는 것이 목표이다.


## 📌 Switching fabrics (스위칭 패브릭)

### 🔹 기능

- 입력 링크로 들어온 패킷을 **적절한 출력 링크로 전송**하는 하드웨어 구조를 의미합니다.

### 🔹 Switching rate (스위칭 속도)

- 패킷이 입력에서 출력으로 **전송될 수 있는 속도**를 의미합니다.
- 일반적으로 **입·출력 회선 속도의 배수**로 표현됩니다.
- 입력 포트가 **N개**라면, **스위칭 속도가 회선 속도의 N배가 되는 것이 이상적**입니다.  
    → 모든 입력에서 동시에 패킷이 들어오더라도 병목 없이 전달할 수 있기 때문입니다.

## 🔹 스위칭 패브릭의 세 가지 주요 구조

| 유형                                  | 개념                                           | 장점             | 단점                                |
| ----------------------------------- | -------------------------------------------- | -------------- | --------------------------------- |
| Memory (메모리 기반)                     | CPU가 입력 포트에서 패킷을 읽어 메모리에 저장한 뒤 출력 포트로 보내는 방식 | 가장 단순함         | CPU 성능 한계로 병렬 처리 불가 → 속도 낮음       |
| Bus (버스 기반)                         | 모든 포트가 공유하는 버스를 통해 입력 → 출력으로 패킷 전달           | 구현이 쉽고 확장 용이   | 한 번에 한 패킷만 버스를 사용할 수 있어 충돌·대역폭 제한 |
| Interconnection network (상호연결 네트워크) | 여러 스위치·경로를 이용하여 입력과 출력을 다중 연결                | 높은 병렬성 및 고속 처리 | 구조가 복잡하며 비용이 높음                   |

### 🔍 핵심 비교 요약

| 속도 | 메모리 < 버스 < 상호연결 네트워크 |  
| 병렬성 | 메모리: 없음 → 버스: 제한적 → 상호연결 네트워크: 높음 |  
| 실제 고성능 라우터 | 대부분 **상호연결 네트워크 방식** 사용 |

### ✔ 한 문장 요약

> 스위칭 패브릭은 입력 포트의 패킷을 출력 포트로 전달하는 라우터 내부의 핵심 하드웨어이며, 성능은 **메모리 방식 → 버스 방식 → 상호연결 네트워크 방식** 순으로 향상됩니다.


## 📌 Switching via memory — 번역

**first generation routers:**

- 전통적인 컴퓨터에서 CPU가 스위칭을 직접 제어하는 방식
- 패킷이 시스템 메모리로 복사됨
- 메모리 대역폭에 의해 속도가 제한됨 (각 데이터그램당 버스를 두 번 횡단해야 함)

그림 설명:  
입력 포트(예: Ethernet) → **시스템 버스**를 통해 패킷을 **메모리**에 복사 → 다시 시스템 버스를 통해 **출력 포트**로 복사


## 📌 Switching via a bus — 번역

- 공유 버스를 통해 **입력 포트 메모리에서 출력 포트 메모리로** 데이터그램을 전송한다.
- **bus contention**: 버스 대역폭으로 인해 스위칭 속도가 제한된다.
- 32 Gbps 버스를 사용하는 Cisco 6500 장비는 액세스 라우터 용도로는 충분한 속도를 제공한다.


## 📌 Switching via interconnection network — 번역

- 크로스바(Crossbar), 클로스 네트워크(Clos networks), 그리고 기타 상호연결(interconnection) 네트워크들은  
    원래 다중 프로세서(multiprocessor) 환경에서 프로세서들을 연결하기 위해 개발되었다.

- **multistage switch**: 여러 단계의 소형 스위치를 조합하여 구성된 **n×n 스위치**    
- **병렬성(parallelism) 활용:**
    - 데이터그램을 진입 시 고정 길이 셀로 분할한다.
    - 셀 단위로 스위칭 패브릭을 통과시키고, 출구에서 다시 데이터그램으로 재조립한다.


## 📌 Input port queuing — 번역

- 스위칭 패브릭이 **입력 포트들의 합산 처리 속도보다 느린 경우**,  
    → 입력 큐에서 대기가 발생할 수 있다.
    - 입력 버퍼 오버플로우로 인해 **큐잉 지연 및 패킷 손실**이 발생할 수 있다.

- **Head-of-the-Line (HOL) blocking**:  
    큐의 가장 앞에 있는 데이터그램 때문에  
    뒤에 있는 다른 데이터그램들이 **앞으로 이동하지 못하는 현상**    

### 그림 설명 (좌측)

- 출력 포트 경쟁(output port contention) 상황에서는  
    하나의 빨간 데이터그램만 전송될 수 있다.    
- 아래 줄의 빨간 데이터그램은 **차단(blocked)** 되어 전달되지 못한다.

### 그림 설명 (우측)

- 한 패킷 시간이 지나면 초록 패킷이 스위칭을 시도하지만,  
    앞줄의 패킷 때문에 **HOL 블로킹을 경험**하게 된다.


## 📌 Output port queueing — 번역

- **패킷 스위치 패브릭의 전송 속도**가 링크의 전송 속도보다 빠를 경우, **출력 포트에서 큐잉이 발생할 수 있습니다.**
- **버퍼링(buffering)**은 데이터그램이 패브릭에서 링크로 전달되는 속도보다 더 빠르게 도착할 때 필요합니다.
    - **Drop policy**: 사용 가능한 버퍼가 없을 때 **어떤 데이터그램을 삭제할지** 결정하는 정책입니다.

- **Scheduling discipline**은 **전송을 위해 큐에 저장된 데이터그램들 중 어떤 것을 먼저 보낼지** 결정하는 방식입니다.    

오른쪽 설명:

- **혼잡(congestion)과 버퍼 부족으로 인해 데이터그램이 손실될 수 있습니다.**
- **우선순위 스케줄링(priority scheduling)**은 **어떤 트래픽이 더 높은 성능을 보장받는가**를 결정하며, **네트워크 중립성 문제와도 연관됩니다.**


## 📌 Output port queuing (출력 포트 대기열)

### 🔹 슬라이드 번역

- 스위치 패브릭을 통해 도착하는 패킷의 속도가 출력 링크 전송 속도보다 빠르면 **버퍼링(buffering)** 이 필요함.
- **큐잉 지연(queueing delay)** 과 **출력 버퍼 오버플로우로 인한 손실(loss)** 이 발생할 수 있음


### 🔹 설명

스위치 내부에서 패킷이 출력 포트로 몰릴 때, 출력 링크 속도(R)보다 빠르게 패브릭을 거쳐 패킷이 도달하면 출력 포트는 즉시 처리할 수 없음 → 남는 패킷들은 **출력 버퍼(Output buffer)** 에 저장됨.

버퍼가 꽉 차면:

- 새로 들어온 패킷을 버릴지 결정해야 함 → **Drop Policy** 필요    
- 어떤 패킷을 먼저 전송할지 결정 → **Scheduling Discipline** 필요

### 🔹 주요 문제

| 문제                     | 설명                      |
| ---------------------- | ----------------------- |
| Congestion (혼잡)        | 패브릭 → 출력 포트로 패킷이 몰리면 발생 |
| Packet Loss (패킷 손실)    | 버퍼가 꽉 찼을 때 Drop         |
| Queueing Delay (대기 지연) | 출력 링크에 보내기까지 대기 발생      |

### 🔹 출력 포트 큐잉 과정 흐름

1. 시점 t: 여러 입력 포트 → 동일한 출력 포트로 패킷 전달 중    
2. 출력 포트의 한 번 전송 가능한 속도(R)를 초과
3. 초과한 패킷은 **버퍼에 대기**
4. 시간 경과 후 순서대로 전송되지만 지연 발생 가능
5. 버퍼 부족 시 일부 패킷 Drop


# 📘 Buffer Management

## 📌 번역

### **Buffer Management**

네트워크 장비 내부에서는 패킷이 스위치 패브릭을 통해 들어오면, 먼저 **데이터그램 버퍼(queueing scheduling)** 에 저장된다. 이후 **링크 계층 프로토콜(send)** 을 거쳐 **라인 종단(line termination)** 을 통해 전송된다.

### **Abstraction: queue**

패킷이 도착하면 큐(대기 구역)에 저장되고, 링크(서버)에 의해 순차적으로 처리되어 전송된다.

## **Buffer management:**

### **1. Drop(삭제)**

버퍼가 가득 찼을 때 어떤 패킷을 버릴지 결정하는 메커니즘이다.

- **Tail drop**: 도착한 새 패킷을 즉시 버림
- **Priority drop**: 우선순위에 따라 패킷을 선택적으로 제거함

### **2. Marking(마킹)**

혼잡을 보내는 쪽에 알리기 위해 특정 패킷에 표시를 추가함  
– 사용 예: **ECN**, **RED**

# 📌 요약

- **버퍼 관리(Buffer Management)** 는 스위치 내부에서 패킷을 저장하고 처리하는 과정에서 **어떤 패킷을 버릴지(drop)**, **어떤 패킷을 혼잡 표시(marking)** 할지 결정하는 기술이다.
- **Drop 방식**에는 도착 패킷을 바로 버리는 _tail drop_, 우선순위 기반 제거인 _priority drop_이 있다.
- **Marking 방식**은 네트워크 혼잡을 알리기 위해 패킷에 표시를 하고, ECN·RED 같은 혼잡 제어 메커니즘에서 사용된다.


# 📘 Packet Scheduling: FCFS

### **Packet scheduling**

링크에서 다음으로 어떤 패킷을 전송할지 결정하는 방식이다.  
대표적인 스케줄링 방식은 다음과 같다.

- **first come, first served**
- **priority**
- **round robin**
- **weighted fair queueing**

### **Abstraction: queue**

패킷이 도착하면 큐(대기구역)에 저장되고, 링크(서버)에 의해 순서대로 전송된다.

### **FCFS (First Come, First Served)**

도착한 순서대로 패킷을 출력 포트로 전송하는 방식이다.
- **FIFO(First-In-First-Out)** 로도 불린다.
- 실세계 예: 은행 대기줄, 주차장 입구 순번, 티켓 줄 등

# 📌 요약

- **패킷 스케줄링**은 링크에서 어떤 패킷을 먼저 보낼지 결정하는 과정이다.    
- 대표 방식: FCFS, 우선순위(priority), 라운드 로빈, WFQ 등
- **FCFS(FIFO)** 는 패킷이 들어온 순서대로 처리하는 가장 단순한 방식이다.
- 실생활에서도 흔히 볼 수 있는 "선착순" 처리 방식과 동일하다.


# 📘 Scheduling Policies: Priority

## 📌 번역

### **Priority scheduling**

- 도착하는 트래픽은 우선순위(class)에 따라 분류되고, 각 클래스별 큐에 저장된다.
    - 분류에는 헤더의 어떤 필드라도 사용할 수 있다.

- 전송 시에는 **버퍼에 패킷이 존재하는 가장 높은 우선순위 큐**에서 먼저 선택하여 보낸다.    
    - 같은 우선순위 클래스 내부에서는 **FCFS 방식**으로 처리된다.


## 📌 요약

- **우선순위 스케줄링(priority scheduling)** 은 패킷을 **등급(class)** 으로 나누어 큐에 저장하고,  
    **우선순위가 가장 높은 큐부터 패킷을 전송**하는 방식이다.    
- 각 클래스 내부에서는 FCFS처럼 선착순 처리한다.
- 장점: 긴급 트래픽(예: 음성, 제어 신호 등)을 빠르게 전송할 수 있음
- 단점: 낮은 우선순위 트래픽이 계속 밀려 **기아(starvation)** 가 발생할 수 있음



# 📘 Scheduling Policies: Round Robin

## 📌 번역

### **Round Robin (RR) scheduling**

- 도착한 트래픽은 우선순위 클래스별로 분류되어 각각의 큐에 저장된다.
    - 분류에는 헤더의 어떤 필드라도 사용할 수 있다.

- 서버는 **순환적으로(cyclically)** 각 클래스 큐를 반복적으로 스캔하며,  
    **각 클래스에서 하나의 패킷이 존재하면 1개씩 번갈아가며 전송**한다.    

## 📌 요약

- **라운드 로빈(RR)** 은 여러 클래스가 있을 때 **각 클래스에 공평하게 서비스**를 제공하기 위해  
    한 클래스에서 **한 개씩** 패킷을 꺼내 전송하는 방식이다.    
- 모든 클래스에 균등한 기회를 주므로, 단일 클래스가 링크를 독점할 수 없다.
- 단점: 패킷 크기가 다르면 공평성이 왜곡될 수 있음 → **WFQ가 등장하는 이유**


# 📘 Scheduling Policies: Weighted Fair Queueing

## 📌 번역

### **Weighted Fair Queueing (WFQ)**

- WFQ는 **라운드 로빈(RR)의 일반화된 형태**이다.
- 각 클래스 iii 는 **가중치 wiw_iwi​** 를 가지며,  
    한 사이클에서 **가중치 비율만큼 서비스량**을 배정받는다:

w_i/∑_j w_j​​

- 이를 통해 **트래픽 클래스별 최소 대역폭(minimum bandwidth)** 을 보장할 수 있다.

## 📌 요약

- **WFQ**는 단순한 라운드 로빈과 달리,  
    **클래스마다 서로 다른 비중(가중치)** 을 부여하여 서비스 비율을 조절하는 방식이다.
- 각 클래스는 가중치에 비례한 양의 패킷이 서비스되므로,  
    **대역폭 할당을 정교하게 제어**할 수 있다.
- 장점: 서비스 품질(QoS) 보장, 클래스별 최소 대역폭 확보
- RR보다 공평하며, Priority Queue보다 starvation 문제가 없다


# 📘 IP Datagram Format

## 📌 번역

### **IP 헤더 필드 설명**

- **version**  
    IP 프로토콜 버전 번호(IPv4/IPv6).
- **header length (IHL)**  
    헤더 길이(바이트 단위).
- **type of service (ToS)**  
    패킷 우선순위 관련 필드.
    - DiffServ(비트 0~5)
    - ECN(비트 6~7)
- **total length**  
    전체 IP 데이터그램 길이(바이트).  
    최대 약 64KB, 일반적으로 1500바이트 이하(MTU).
- **16-bit identifier, flags, fragment offset**  
    단편화(fragmentation) 및 재조립(reassembly)에 사용됨.
- **TTL (Time To Live)**  
    남은 최대 홉 수. 각 라우터를 지날 때마다 1씩 감소.
- **upper layer protocol**  
    상위 계층 프로토콜(TCP, UDP 등)을 나타냄.
- **header checksum**  
    IP 헤더에 대한 오류 검출용 체크섬.
- **source IP address**  
    32비트 출발지 IP 주소.
- **destination IP address**  
    32비트 목적지 IP 주소.
- **options** (있을 경우)  
    예: 타임스탬프, 경로 기록 등.
- **payload data**  
    가변 길이 데이터. 보통 TCP/UDP 세그먼트가 포함됨.

### **Overhead**

- TCP 헤더: 20 bytes    
- IP 헤더: 20 bytes  
    → TCP/IP 기본 오버헤드 = **40 bytes + 애플리케이션 계층 오버헤드**
# 📌 요약

- IP 데이터그램은 **고정된 헤더 부분 + 가변 길이 페이로드**로 구성된다.    
- 주요 기능: **라우팅, 단편화, 오류 검출, QoS 정보 전달**
- 헤더는 출발지·목적지 주소, TTL, 프로토콜 정보, 단편화 정보 등을 포함한다.
- TCP/IP 스택에서 최소 **40바이트의 헤더 오버헤드**가 발생한다.


# 📘 IP Fragmentation / Reassembly

## 📌 번역

### **IP 단편화(fragmentation)**

- 네트워크 링크는 **MTU(Maximum Transfer Unit)** 를 가지며, 이는 링크 계층에서 전송할 수 있는 최대 프레임 크기이다.
    - 링크 종류마다 MTU 값이 다르다.

- 큰 크기의 IP 데이터그램은 네트워크 내부에서 **여러 조각(fragment)** 으로 분할된다.    
    - 하나의 데이터그램이 여러 개의 작은 데이터그램으로 나뉨.

- 단편화된 여러 조각은 **목적지에서만(reassembly)** 다시 원래 데이터그램으로 재조립된다.    
- IP 헤더의 특정 비트(Identifier, Flags, Fragment offset)가  
    조각을 식별하고 순서를 재구성하는 데 사용된다.

## 📌 요약

- MTU 제한 때문에 큰 IP 데이터그램은 네트워크 경로 중간에서 **강제 단편화**될 수 있다.    
- 단편화는 **라우터에서 발생**, 재조립은 **목적지에서만 수행**된다.
- IP 헤더는 조각들의 순서와 위치를 표시하여 재조립이 가능하도록 만든다.
- 단편화는 성능 저하 및 패킷 손실 확률 증가를 유발하므로 실제 네트워크에서는 주로 **Path MTU Discovery(PMTUD)** 를 사용하여 회피한다.


# 📘 IP Fragmentation/Reassembly – Example

## 📌 번역

### **예제 조건**

- 원래 IP 데이터그램 크기: **4000 bytes**
- MTU: **1500 bytes**

### **단편화 과정**

- IP 헤더가 20 bytes 이므로,  
    각 fragment의 **데이터(payload)** 는  
    **1500 − 20 = 1480 bytes**까지 담을 수 있다.
- 데이터그램은 아래와 같이 3개의 조각으로 분할된다.
1. **첫 번째 fragment**
- length = 1500
- fragflag = 1 (더 많은 fragment가 있음)
- offset = 0

2. **두 번째 fragment**
- length = 1500
- fragflag = 1
- offset = 1480 / 8 = 185

3. **세 번째 fragment**
- 남은 데이터: 4000 − (1480 × 2) = 1040 bytes
- length = 1040 + 20 = 1060 (헤더 포함)
- fragflag = 0 (마지막 fragment)
- offset = (1480 × 2) / 8 = 370

## 📌 요약

- MTU(1500 bytes)를 넘는 4000-byte 데이터그램은 **3개의 fragment**로 나뉜다.    
- 각 fragment는 최대 **1480 bytes의 데이터**를 가진다(헤더 20 bytes 제외).
- offset은 항상 **8-byte 단위**로 계산된다.
- 마지막 fragment는 **fragflag = 0**, 이전 fragment들은 **fragflag = 1**이다.

# 📘 IP Addressing: Introduction

## 📌 번역

### **IP address**
- IP 주소는 **32비트 식별자**이며, 각 호스트(host) 또는 라우터(router)의 **인터페이스(interface)** 에 할당된다.

### **interface**
- 인터페이스는 **호스트/라우터와 물리적 링크를 연결하는 접점**이다.
- 라우터는 보통 **여러 개의 인터페이스**를 가진다.
- 일반적인 호스트(PC, 스마트폰 등)는 **1~2개의 인터페이스**만 가진다.  
    예: 유선 Ethernet, 무선 Wi-Fi(802.11)
### **dotted-decimal IP notation**

예:
- **223.1.1.1** → 11011111 00000001 00000001 00000001  
    (각 8비트 = 1옥텟, 총 32비트)

## 📌 요약

- IP 주소는 **32비트로 구성된 장치의 논리적 식별자**이다.
- 실제로는 ‘장치 전체’가 아니라 **인터페이스마다 각각 IP 주소를 부여**한다.  
    → 하나의 라우터가 여러 IP를 가지는 이유.
- 호스트는 보통 하나의 인터페이스(Ethernet 또는 Wi-Fi)를 사용한다.    
- IP 주소는 **점-십진 표기(dotted decimal)** 로 작성되며, 이는 32비트 값을 옥텟 단위로 나눈 표현이다.

# 📘 IP Addressing: Introduction (Interfaces)

## 📌 번역

### Q: 인터페이스들은 실제로 어떻게 연결되는가?

A: 이 내용은 **6장**에서 배울 예정이다.

- **유선 연결(wired Ethernet)**  
    → 이더넷 스위치(Ethernet switch)를 통해 여러 Ethernet 인터페이스가 연결된다.    
- **무선 연결(wireless WiFi)**  
    → WiFi 베이스 스테이션(무선 AP)을 통해 WiFi 인터페이스들이 연결된다.

### For now

- 지금은 “라우터 없이 인터페이스끼리 어떻게 연결되는지”에 대해 걱정할 필요는 없다.

## 📌 요약

- IP 주소는 인터페이스에 붙지만, **인터페이스들이 실제로 어떻게 물리적으로 연결되는지**는 더 뒷부분(6장)에서 다룬다.    
- 유선 장비는 **스위치**, 무선 장비는 **WiFi AP**를 통해 인터페이스들이 연결된다.
- 현재 단계에서는 단순히 “인터페이스는 어떤 방식으로든 연결되어 있다” 정도만 알고 있으면 충분하다.


# 📘 Subnets

## 📌 번역 (1) — What’s a subnet?

### **What’s a subnet?**

- 서브넷(subnet)은 **라우터를 거치지 않고 물리적으로 서로 도달 가능한** 장치 인터페이스들의 집합이다.
### **IP addresses have structure**

- **subnet part**: 같은 서브넷에 속한 장치들은 IP 주소의 **상위 비트(high-order bits)** 를 공유한다.
- **host part**: 나머지 **하위 비트(low-order bits)** 는 같은 서브넷 내의 개별 장치를 구분한다.

그림의 예는 총 **3개의 서브넷**으로 구성된 네트워크이다.

## 📌 번역 (2) — How to define subnets

### **Recipe for defining subnets**

- 각 인터페이스를 호스트나 라우터로부터 분리하여 **유사한 인터페이스들의 고립된 네트워크 섬(섬 형태의 그룹)** 을 만든다.
- 이러한 **고립된 네트워크 하나가 서브넷(subnet)** 이다.

### **서브넷 예 (CIDR 표기)**

- subnet **223.1.1.0/24**
- subnet **223.1.2.0/24**
- subnet **223.1.3.0/24**

### **Subnet mask**
- `/24` = 상위 24비트가 서브넷 부분
- 나머지 8비트는 host part

# 📌 요약

- **서브넷(subnet)** 은 라우터를 거치지 않고 도달 가능한 장치 인터페이스들의 집합이다.    
- IP 주소는 **subnet part(상위 비트)** + **host part(하위 비트)** 로 구성된다.
- CIDR 표기 `/24`는 상위 24비트가 네트워크 주소임을 의미한다.
- 서브넷을 정의하는 과정은 네트워크를 여러 “고립된 섬”으로 나누는 것과 같다.
- 위 그림의 네트워크는 **/24로 구성된 3개의 서브넷**(223.1.1.0/24, 223.1.2.0/24, 223.1.3.0/24)으로 이루어져 있다.


# 📘 IP Addressing: CIDR

## 📌 번역

### **CIDR (Classless InterDomain Routing)**

- “사이더(cider)”로 발음된다.
- 서브넷 부분(subnet part)의 길이를 **임의로 설정할 수 있는** 주소 체계이다.
- 주소 형식:

a.b.c.d/x
여기서 **x는 서브넷 부분의 비트 수**이다.

### 예시

이진 표현:
`11001000 00010111 00010000 00000000`
- 왼쪽부터 `/23`까지는 **subnet part**
- 나머지 비트는 **host part**

CIDR 표기:  
**200.23.16.0/23**

## 📌 요약

- CIDR은 기존 클래스 기반(Class A/B/C)의 고정 길이 네트워크 부분을 없애고,  
    **서브넷 길이를 원하는 만큼(x 비트) 지정할 수 있게 만든 방식**이다.    
- 주소는 **a.b.c.d/x** 형태로 표기되며, x는 **네트워크(bit) 구간의 길이**를 의미한다.
- 예: `/23` → 첫 23비트가 네트워크(subnet), 나머지 9비트가 호스트(host) 역할.


## 문제 번역

어떤 라우터가 세 개의 서브넷 **Subnet 1, Subnet 2, Subnet 3** 를 상호 연결하고 있다고 가정한다.  
세 서브넷의 모든 인터페이스는 **223.1.17/24** 프리픽스를 가져야 한다고 하자.

또한 다음과 같은 요구 사항이 있다.

- **Subnet 1**: 최대 **62개의 인터페이스**를 지원해야 함
- **Subnet 2**: 최대 **106개의 인터페이스**를 지원해야 함
- **Subnet 3**: 최대 **15개의 인터페이스**를 지원해야 함

이 조건을 만족하는, **a.b.c.d/x** 형태의 세 개의 네트워크 주소를 구하라.

## 풀이 과정

기본 네트워크: **223.1.17.0/24**  
→ 전체 주소 개수: 232−24=28=2562^{32-24} = 2^8 = 256232−24=28=256개

각 서브넷이 필요로 하는 **호스트(인터페이스) 수** 를 만족하려면  
서브넷당 usable host 수 =2h−2= 2^{h} - 2=2h−2 가 요구 개수 이상이 되어야 합니다.  
(여기서 hhh = 호스트 비트 수)

### 1) Subnet 1: 62개 필요

2h−2≥622^{h} - 2 \ge 622h−2≥62

- h=6h = 6h=6: 26−2=64−2=622^6 - 2 = 64 - 2 = 6226−2=64−2=62 → 정확히 만족  
    → 프리픽스 길이: 32−6=2632 - 6 = 2632−6=26  
    → **Subnet 1 → /26** 필요
    

### 2) Subnet 2: 106개 필요

2h−2≥1062^{h} - 2 \ge 1062h−2≥106

- h=6h = 6h=6: 64−2=62<10664 - 2 = 62 < 10664−2=62<106 (불충분)
    
- h=7h = 7h=7: 128−2=126≥106128 - 2 = 126 \ge 106128−2=126≥106 (충분)
    

→ 프리픽스 길이: 32−7=2532 - 7 = 2532−7=25  
→ **Subnet 2 → /25** 필요

### 3) Subnet 3: 15개 필요

2h−2≥152^{h} - 2 \ge 152h−2≥15

- h=4h = 4h=4: 16−2=14<1516 - 2 = 14 < 1516−2=14<15
    
- h=5h = 5h=5: 32−2=30≥1532 - 2 = 30 \ge 1532−2=30≥15


→ 프리픽스 길이: 32−5=2732 - 5 = 2732−5=27  
→ **Subnet 3 → /27** 필요

### 4) /24 안에서 주소 블록 배치

기본 네트워크 223.1.17.0/24 안에서, 큰 서브넷부터 차례로 할당합니다.

- **Subnet 2 (가장 큼, /25 = 128주소)**
    - 네트워크 주소: **223.1.17.0/25**
    - 사용 범위: 223.1.17.0 ~ 223.1.17.127

- **Subnet 1 (/26 = 64주소)**    
    - 다음 블록 시작: 223.1.17.128
    - 네트워크 주소: **223.1.17.128/26**
    - 사용 범위: 223.1.17.128 ~ 223.1.17.191

- **Subnet 3 (/27 = 32주소)**    
    - 다음 블록 시작: 223.1.17.192
    - 네트워크 주소: **223.1.17.192/27**
    - 사용 범위: 223.1.17.192 ~ 223.1.17.223


이렇게 하면 세 서브넷이 서로 겹치지 않고,  
각각 필요한 인터페이스 수를 모두 만족하며,  
모두 223.1.17.0/24 범위 안에 들어갑니다.

## 최종 답

조건을 만족하는 한 가지 예시는 다음과 같습니다.

- **Subnet 2**: `223.1.17.0/25` (최대 126 인터페이스)
- **Subnet 1**: `223.1.17.128/26` (최대 62 인터페이스)
- **Subnet 3**: `223.1.17.192/27` (최대 30 인터페이스)

문제는 단지 “조건을 만족하는 세 네트워크 주소”를 요구하므로,  
위와 같이 비겹치게만 나누면 정답이 됩니다.


## IP addresses: how to get one?

### 번역

IP 주소를 얻는 과정에는 사실 두 가지 질문이 존재합니다.

1. **호스트는** 자신의 네트워크 내부에서 **어떻게 IP 주소(주소의 host 부분)를 부여받는가?**
2. **네트워크는** 스스로를 식별하기 위한 **IP 주소(주소의 network 부분)를 어떻게 부여받는가?**

### 호스트는 어떻게 IP 주소를 얻는가?

- 시스템 관리자가 설정 파일(예: UNIX의 `/etc/rc.config`)에 **정적으로 직접 설정하는 방식**
- **DHCP(Dynamic Host Configuration Protocol)**
    - 서버로부터 IP 주소를 **동적으로 할당**받는 방식
    - “plug-and-play”가 가능함

## 요약

- IP 주소 획득에는 **호스트 단의 주소 할당**과 **네트워크 단의 주소 할당**이라는 두 관점이 존재함. 
- 호스트는 **정적 설정** 또는 **DHCP를 통한 동적 할당** 방식으로 IP 주소를 부여받음.


## DHCP: Dynamic Host Configuration Protocol

### 목표

DHCP의 목표는 호스트가 네트워크에 “가입(join)”할 때 **네트워크 서버로부터 IP 주소를 동적으로 부여받도록 하는 것**입니다.

- 사용 중인 주소에 대해 **임대 기간(lease)을 갱신**할 수 있음
- 주소의 **재사용이 가능함**(연결되어 있는 동안에만 주소를 보유)
- 네트워크에 접속하거나 떠나는 **모바일 사용자에게 유용함**

### DHCP 동작 개요

- 호스트가 **DHCP discover** 메시지를 브로드캐스트함 _(선택적)_    
- DHCP 서버가 **DHCP offer** 메시지로 응답함 _(선택적)_
- 호스트가 **DHCP request** 메시지를 보내 주소를 요청함
- DHCP 서버가 **DHCP ack** 메시지를 보내 주소를 최종적으로 할당함

## 요약

DHCP는 호스트가 네트워크에 접속할 때 IP 주소를 자동으로 부여하는 프로토콜이며, discover → offer → request → ack의 순서로 주소가 할당된다.


## DHCP client–server scenario

일반적으로 DHCP 서버는 **라우터 내부에 함께 배치(co-located)**되어 있으며, 라우터가 연결된 **모든 서브넷(subnet)**에 대해 주소 할당 서비스를 제공합니다.

네트워크에 새로 도착한 **DHCP 클라이언트는** 이 네트워크에서 사용할 **IP 주소가 필요**합니다.

그림에서는 여러 서브넷(223.1.1.x, 223.1.2.x, 223.1.3.x)이 라우터에 연결되어 있으며, DHCP 서버(223.1.2.5)가 이 모든 서브넷에 걸쳐 IP 주소를 할당하는 구조를 보여줍니다.

## 요약

- DHCP 서버는 보통 **라우터 안에 포함**되어 여러 서브넷을 동시에 관리함.    
- 새로 접속하는 장치는 DHCP 클라이언트로서 **IP 주소 할당**을 요청함.
- 하나의 DHCP 서버가 라우터를 통해 여러 네트워크 대역에 주소를 제공할 수 있음.


## DHCP client–server scenario

도착한 클라이언트는 네트워크에 접속하기 위해 IP 주소가 필요합니다. DHCP 절차는 다음과 같은 네 단계로 이루어집니다.

### 1) DHCP Discover

클라이언트가 브로드캐스트로 **“DHCP 서버가 있습니까?”**라는 메시지를 보냅니다.

- src: 0.0.0.0, port 68
- dest: 255.255.255.255, port 67
- yiaddr: 0.0.0.0
- transaction ID: 654

### 2) DHCP Offer

DHCP 서버가 브로드캐스트로 응답하며 **“여기 사용 가능한 IP 주소가 있습니다.”**라고 알립니다.

- src: 223.1.2.5, port 67
- dest: 255.255.255.255, port 68
- yiaddr: 223.1.2.4
- transaction ID: 654
- lifetime: 3600초

### 3) DHCP Request

클라이언트가 브로드캐스트로 **“해당 IP 주소를 사용하고 싶습니다.”**라고 요청합니다.

- src: 0.0.0.0, port 68
- dest: 255.255.255.255, port 67
- yiaddr: 223.1.2.4
- transaction ID: 655
- lifetime: 3600초

### 4) DHCP ACK

서버가 **“해당 IP 주소를 할당했습니다.”**라고 최종 승인 메시지를 보냅니다.

- src: 223.1.2.5, port 67
- dest: 255.255.255.255, port 68
- yiaddr: 223.1.2.4
- lifetime: 3600초

### 참고

RFC 2131에 따르면, 클라이언트가 이전에 할당받았던 주소를 기억하고 있으며 이를 재사용하려는 경우, Discover/Offer 단계를 **건너뛸 수 있습니다**.

## 요약

- DHCP는 **Discover → Offer → Request → ACK**의 4단계를 통해 IP 주소를 동적으로 할당합니다.    
- 모든 단계는 브로드캐스트로 이루어지므로 클라이언트가 네트워크에 처음 참여할 때도 서버를 찾을 수 있습니다.
- 주소 재사용이 가능한 경우, 일부 단계가 생략될 수 있습니다.


## DHCP: more than IP addresses

### 번역

DHCP는 서브넷에서 할당된 IP 주소뿐 아니라 다음과 같은 추가 정보를 함께 제공할 수 있습니다.

- 클라이언트가 사용하는 **첫 번째 홉(first-hop) 라우터의 주소**
- **DNS 서버의 이름과 IP 주소**
- **네트워크 마스크**(주소에서 네트워크 부분과 호스트 부분을 구분하는 정보)

## 요약

DHCP는 단순히 IP 주소만 주는 것이 아니라, 라우터 정보, DNS 정보, 서브넷 마스크 등 네트워크 통신에 필요한 여러 구성 정보를 함께 제공한다.


## DHCP: example

### 번역

- 노트북이 네트워크에 연결되면 DHCP를 사용하여 **IP 주소**, **첫 번째 홉 라우터의 주소**, **DNS 서버의 주소**를 부여받습니다.
- DHCP REQUEST 메시지는  
    **UDP 안에 캡슐화**,  
    그 UDP는 **IP 안에 캡슐화**,  
    그리고 그 IP는 **이더넷 프레임 안에 캡슐화**되어 전송됩니다.
- 이더넷 프레임은 LAN에서 **브로드캐스트**됩니다.  
    (목적지 주소: `FF:FF:FF:FF:FF:FF`)  
    이 프레임은 DHCP 서버 기능을 갖춘 라우터에 도달합니다.
- 라우터는 이더넷 계층에서 메시지를 수신해 **IP 계층으로 디멀티플렉스**(demux)하고,  
    다시 IP 계층에서 **UDP로 디멀티플렉스**,  
    이후 UDP에서 **DHCP로 전달**합니다.

## 요약

DHCP 메시지는 이더넷 → IP → UDP → DHCP 순으로 캡슐화되어 브로드캐스트되며, 라우터의 DHCP 서버가 이를 받아 필요한 네트워크 구성 정보를 노트북에 제공한다.


- DHCP 서버는 DHCP ACK 메시지를 생성하여, 클라이언트의 **IP 주소**, **첫 번째 홉 라우터의 주소**, **DNS 서버의 이름과 IP 주소**를 포함하여 전달합니다.
- 캡슐화된 DHCP 서버의 응답은 클라이언트에게 전달되며, 클라이언트 측에서 **DHCP 계층까지 차례대로 디멀티플렉스**됩니다.
- 이제 클라이언트는 다음 정보를 모두 알게 됩니다.
    - 자신의 IP 주소
    - DNS 서버의 이름과 IP 주소
    - 첫 번째 홉 라우터의 IP 주소

## 요약

DHCP ACK 메시지를 통해 클라이언트는 최종적으로 자신의 IP 주소뿐 아니라 기본 라우터와 DNS 서버 정보까지 모두 전달받고 네트워크 설정을 완료한다.


## IP addresses: how to get one?

**Q:** 네트워크는 IP 주소의 서브넷 부분을 어떻게 부여받는가?  
**A:** 상위 제공자 ISP로부터 **주소 공간의 일부를 할당받아** 사용한다.

예시로, ISP가 다음과 같은 주소 블록을 보유한다고 가정한다.

- ISP의 블록:  
    `11001000 00010111 00010000 00000000` → **200.23.16.0/20**    

ISP는 이 /20 주소 공간을 8개의 작은 블록으로 나누어 여러 조직에 할당할 수 있다.

예시:

- Organization 0 → `200.23.16.0/23`
- Organization 1 → `200.23.18.0/23`
- Organization 2 → `200.23.20.0/23`
- ...
- Organization 7 → `200.23.30.0/23`
## 요약

네트워크는 자체적으로 서브넷을 만드는 것이 아니라, **ISP가 보유한 큰 주소 공간(/20 등)을 여러 개의 작은 블록(/23 등)으로 나누어 조직에 분배함으로써** 서브넷 주소를 얻게 된다.



## Hierarchical addressing: more specific routes

- **Organization 1이 기존 ISP(Fly-By-Night-ISP)에서 다른 ISP(ISPs-R-Us)로 이동**하였다.
- 이에 따라 ISPs-R-Us는 Organization 1에 대해 **더 구체적인(specific) 경로**를 광고한다.

그림 설명:  
기존에는 Fly-By-Night-ISP가 `200.23.16.0/20` 범위 전체를 인터넷에 광고하며,

> “200.23.16.0/20으로 시작하는 주소는 모두 나에게 보내라.”  
> 라고 알렸다.

하지만 Organization 1(200.23.18.0/23)이 다른 ISP(ISPs-R-Us)로 이동하면,  
ISPs-R-Us는 다음과 같이 더 구체적인 경로를 광고한다.

- “199.31.0.0/16 주소는 나에게 보내라”
- **“그리고 200.23.18.0/23도 나에게 보내라”** ← 더 specific한 경로

인터넷 라우터들은 longest-prefix rule(최장 접두어 매칭)을 적용하므로,  
`200.23.18.0/23`을 향한 트래픽은 더 구체적인 경로를 제공하는 ISPs-R-Us로 보내지게 된다.

## 요약

- Organization 1이 ISP를 변경하면, 새 ISP는 해당 조직의 주소 범위(/23)를 **더 구체적인 경로**로 인터넷에 광고한다.    
- 인터넷 라우터는 **가장 구체적인(prefix 길이가 긴) 경로**를 우선 사용하므로,  
    Organization 1의 주소로 가는 패킷은 자연스럽게 새 ISP로 전달된다.
- 이는 계층적 주소 체계에서 **prefix 기반 라우팅의 핵심 원리**이다.


## IP addressing: last words …

### 1) ISP는 주소 블록을 어떻게 받는가?

**Q:** ISP는 어떻게 IP 주소 블록을 확보하는가?  
**A:** **ICANN(Internet Corporation for Assigned Names and Numbers)**이 전 세계 IP 주소 관리를 총괄한다.  
사이트: http://www.icann.org/

ICANN의 역할:
- **5개 지역 인터넷 등록기관(RR, Regional Registries)**을 통해 IP 주소를 분배한다.  
    (각 RR은 필요할 경우 국가/지역 단위의 하위 등록기관에 다시 주소를 분배함)
- **DNS 루트 존(root zone)**을 관리하며,  
    `.com`, `.edu` 등 개별 TLD(Top-Level Domain)의 관리 권한을 위임함.

### 2) 32비트 IPv4 주소는 충분한가?

**Q:** 32비트 IP 주소는 충분한가?  
**A:** 현실적으로 부족하다.
- ICANN은 **2011년에 마지막 IPv4 주소 블록을 지역 등록기관에 모두 할당함** → 사실상 IPv4 고갈
- **NAT(Network Address Translation)**은 IPv4 주소 부족 문제를 어느 정도 완화함
- **IPv6는 128비트 주소 공간**을 제공하여 사실상 주소 고갈 문제를 해결함

마지막 인용문:

> “도대체 얼마나 많은 주소 공간이 필요할 줄 누가 알았겠는가?”  
> — IPv4 주소 길이를 32비트로 결정한 당시를 회고하며, Vint Cerf

## 요약

- 전 세계 IP 주소는 ICANN이 관리하며, 지역 등록기관을 통해 ISP에 분배된다.    
- IPv4 주소는 이미 고갈되었고, NAT가 임시 해결책으로 사용된다.
- IPv6는 128비트 주소 공간을 제공하여 장기적인 해결책을 제공한다.



## NAT: network address translation

**NAT(Network Address Translation)**:  
로컬 네트워크 내부의 모든 기기는 **외부에서 볼 때 단 하나의 IPv4 주소를 공유**한다.

그림 설명:

- 로컬 네트워크의 주소 범위는 **10.0.0.0/24**이며, 내부 기기들은
    - 10.0.0.1
    - 10.0.0.2
    - 10.0.0.3  
        등의 사설 주소를 사용함.

- 외부 인터넷에서는 이 네트워크 전체가 **138.76.29.7**이라는 하나의 공인 주소로 보임.    

동작 원리:

- 로컬 네트워크를 떠나는 모든 데이터그램은  
    **동일한 NAT IP 주소(138.76.29.7)를 소스 주소로 가지지만**,  
    **서로 다른 소스 포트 번호**를 사용함.
- 반대로, 로컬 네트워크 내부에서의 통신은 기존처럼  
    **10.0.0.0/24 사설 IP 주소**를 그대로 사용함.

## 요약

- NAT는 내부 여러 기기의 주소를 **하나의 공인 IP로 변환**하여 외부에 노출함.    
- 포트 번호를 활용하여 내부 여러 기기와 외부 인터넷 간의 연결을 동시에 유지함.
- IPv4 주소 부족 문제를 완화하는 핵심 기술임.



## NAT: network address translation

- 로컬 네트워크의 모든 기기는 **사설(private) IP 주소 공간**(10/8, 172.16/12, 192.168/16 프리픽스)을 사용하는 32비트 주소를 갖고 있으며, 이 주소들은 로컬 네트워크 내부에서만 사용될 수 있습니다.    

### NAT의 장점

- **단 하나(one)의 공인 IP 주소만** ISP로부터 받으면, 모든 로컬 기기가 인터넷을 사용할 수 있습니다.
- 로컬 네트워크 내부에서 호스트의 주소를 변경해도 **외부 네트워크에 알릴 필요가 없습니다.**
- ISP를 변경하더라도 로컬 네트워크의 주소 체계를 **변경할 필요가 없습니다.**
- 보안 측면에서, 로컬 네트워크 내부의 기기들은 외부에서 **직접 접근할 수 없기 때문에** 외부 세계에 노출되지 않습니다.

## 요약

- 사설 IP 주소는 내부망에서만 사용되며, NAT는 이를 단일 공인 IP로 변환해 외부 인터넷과 통신하게 한다.    
- NAT의 장점은 공인 IP 절약, 내부 주소 구조의 독립성, ISP 변경 시 편의성, 그리고 기본적인 보안성 제공이다.


## NAT: network address translation — implementation

NAT 라우터는 다음 동작을 **투명하게(transparently)** 수행해야 합니다.

### 1) Outgoing datagrams(외부로 나가는 데이터그램 처리)

- 모든 외부로 나가는 데이터그램의 **출발지 IP 주소와 포트 번호를**  
    **(NAT 공인 IP 주소, 새 포트 번호)**로 교체합니다.    
- 외부의 클라이언트/서버는 응답 시  
    **(NAT 공인 IP 주소, 새 포트 번호)**를 목적지로 사용합니다.

### 2) NAT 변환 테이블 기록

- NAT 라우터는 변환 테이블에 다음 항목을 저장해야 합니다.  
    **(내부 출발지 IP 주소, 내부 포트 번호)** → **(NAT 공인 IP 주소, 새 포트 번호)**  
    (이 매핑 정보를 통해 나중에 응답을 올바른 내부 기기로 전달할 수 있음)

### 3) Incoming datagrams(내부로 들어오는 데이터그램 처리)

- 외부에서 들어오는 데이터그램의 목적지 필드에 있는  
    **(NAT 공인 IP 주소, 새 포트 번호)**를  
    NAT 테이블에서 찾은 내부 주소  
    **(내부 출발지 IP 주소, 내부 포트 번호)**로 교체합니다.

- 즉, NAT 테이블에 기록된 매핑을 사용해 올바른 내부 호스트로 전달합니다.  

## 요약

- NAT는 외부로 나가는 패킷의 **IP·포트를 NAT 공인 IP·새 포트로 변환**하고,  
    이 매핑을 테이블에 저장하여  
    외부에서 들어오는 응답 패킷의 목적지를 다시 **내부 호스트의 IP·포트로 변환**한다.    
- 이러한 변환이 모두 “투명하게” 이루어지기 때문에, 내부 기기들은 NAT 존재를 인지하지 않고 정상적으로 통신할 수 있다.


## NAT: network address translation (동작 예시)

### 1) (단계 1)

호스트 **10.0.0.1**이 목적지 **128.119.40.186**, 포트 **80**으로 데이터그램을 전송합니다.

- S: 10.0.0.1, 3345
- D: 128.119.40.186, 80

### 2) (단계 2)

NAT 라우터는 이 데이터그램을 외부로 내보내기 전에 **출발지 주소를 다음과 같이 변경**합니다.

- **내부 주소 10.0.0.1:3345 → 공인 주소 138.76.29.7:5001**    

그리고 NAT 변환 테이블을 다음과 같이 갱신합니다.

| WAN side addr     | LAN side addr  |
| ----------------- | -------------- |
| 138.76.29.7, 5001 | 10.0.0.1, 3345 |

이제 외부로 나가는 데이터그램은 다음과 같이 됩니다.

- S: 138.76.29.7, 5001    
- D: 128.119.40.186, 80

### 3) (단계 3)

외부 서버가 응답을 보냅니다.  
응답 패킷의 목적지 주소는 NAT가 설정한  
**138.76.29.7:5001** 입니다.

- S: 128.119.40.186, 80    
- D: 138.76.29.7, 5001

### 4) (단계 4)

NAT 라우터는 변환 테이블을 확인하고,  
이 패킷을 원래 내부 호스트에게 전달하기 위해 목적지 주소를 다시 변환합니다.

- D: 10.0.0.1, 3345 로 복원하여  
    **10.0.0.1**에게 전달합니다.

## 요약

- NAT는 내부 주소(10.0.0.1:3345)를 공인 주소(138.76.29.7:5001)로 변환하여 외부로 내보냅니다.
- 변환 테이블에 매핑을 저장한 뒤, 외부 응답이 들어오면 이 정보를 사용해 내부 호스트에게 다시 연결해 줍니다.
- 이 과정을 통해 여러 내부 기기가 단 하나의 공인 IP 주소를 공유하면서 인터넷과 통신할 수 있습니다.

## NAT: network address translation

### NAT는 논란의 대상이 되어왔다.

- 라우터는 원래 **OSI 계층 3까지만 처리해야 한다**는 주장과 충돌함.    
- 주소 부족 문제는 **IPv6가 해결해야 한다**는 의견이 있음.
- NAT는 **end-to-end 원칙을 위반**한다.  
    (네트워크 계층 장비가 포트 번호를 조작하기 때문)
- NAT traversal 문제:  
    클라이언트가 NAT 뒤에 있는 서버에 접속하려면 어떻게 할 것인가?

### 그러나 NAT는 계속 사용될 것이다.

- NAT는 **가정용 네트워크**, **기업·학교 네트워크**,  
    **4G/5G 이동통신망**에서 광범위하게 사용되고 있기 때문이다.

## 요약

- NAT는 주소 부족 문제 해결에 효과적이지만,  
    end-to-end 원칙 위반, 포트 조작, 서버 접속 문제 등 여러 비판이 존재한다.    
- 그럼에도 불구하고 NAT는 현재 인터넷 구조에서 실질적으로 필수적이며  
    다양한 환경에서 계속 사용될 것으로 보인다.


## IPv6: motivation

- **초기 도입 동기(initial motivation):**  
    32비트 IPv4 주소 공간이 **곧 완전히 고갈될 것**이라는 점이 IPv6 도입의 출발점이었습니다.    
- **추가적인 도입 동기(additional motivation):**
    - 처리 및 포워딩 속도 향상:  
        IPv6는 **40바이트 고정 길이 헤더**를 사용하여 라우터가 더 빠르게 처리할 수 있습니다.

    - 네트워크 계층에서 서로 다른 **flow(흐름)**에 대해 차별화된 처리가 가능하도록 설계되었습니다.        

## 요약

IPv6는 IPv4 주소 고갈 문제를 해결하기 위해 등장했으며, 고정 길이 헤더를 통해 빠른 처리 성능을 제공하고, 다양한 흐름(flow)을 구분하여 네트워크 계층에서 더 정교한 처리가 가능하도록 한다.


## IPv6 datagram format

### 번역

IPv6 데이터그램의 헤더는 다음과 같은 필드들로 구성됩니다.

- **ver (version)**  
    IPv6 버전을 나타냅니다.
- **pri (priority)**  
    동일한 flow 내 데이터그램 간의 **우선순위**를 구분합니다.
- **flow label**  
    동일한 “flow”에 속하는 데이터그램을 식별하기 위한 값입니다.
- **payload length**  
    페이로드(data) 길이를 나타냅니다.
- **next header**  
    상위 계층 프로토콜(예: TCP, UDP, ICMPv6 등)을 지정합니다.
- **hop limit**  
    IPv4의 TTL(Time To Live)에 해당하며, 경유 가능한 홉(hop)의 최대 수를 나타냅니다.
- **source address (128 bits)**  
    IPv6 출발지 주소
- **destination address (128 bits)**  
    IPv6 목적지 주소

### IPv4와 비교하여 사라진(또는 변경된) 기능들

- **체크섬 없음**  
    → 라우터의 처리 속도를 높이기 위한 설계    
- **단편화(fragmentation) 및 재조립(reassembly) 없음**  
    → 단편화는 오직 출발지 호스트에서만 수행됨
- **옵션 없음**  
    → IPv6에서는 옵션이 별도의 상위(next-header) 확장 헤더로 제공됨

## 요약

IPv6는 128비트 주소, flow label, 고정 길이 헤더 등 IPv4와 다른 구조를 갖고 있으며, 체크섬·단편화·옵션과 같은 일부 기능을 제거하여 처리 속도를 높이고 네트워크 성능을 향상시키도록 설계되었다.


## Transition from IPv4 to IPv6

### 번역

- 모든 라우터를 동시에 IPv6로 업그레이드하는 것은 **불가능**하다.
    - 전체가 동시에 전환되는 “flag day”는 존재하지 않음.
    - 그렇다면 IPv4 라우터와 IPv6 라우터가 혼재하는 동안 네트워크는 어떻게 동작할 것인가?

- **터널링(tunneling)**:  
    혼합 환경에서 IPv6 데이터그램을 IPv4 라우터 사이에서 전달하기 위해  
    **IPv6 데이터그램을 IPv4 데이터그램의 페이로드로 캡슐화하여 운반**한다.  
    (즉, “패킷 안에 패킷” 구조)    
- 터널링 기술은 4G/5G 이동통신망 등 다른 분야에서도 **광범위하게 사용**되고 있다.

아래 그림 설명:

- IPv4 헤더(IPv4 출발지/목적지 포함)가 가장 바깥쪽에 위치하고,  
    그 내부에 IPv6 헤더(IPv6 출발지/목적지 포함)와 IPv6 페이로드가 포함된다.

## 요약

IPv4에서 IPv6로의 전환은 점진적으로 이루어지며, 서로 다른 프로토콜의 라우터가 공존하는 환경을 위해 **터널링 기술**이 사용된다. 이는 IPv6 패킷을 IPv4 패킷 내부에 넣어 전달하는 방식이며, 현대 통신망에서도 폭넓게 활용된다.


## Tunneling and encapsulation

### 1) 일반적인 경우: IPv6 라우터 간의 직접 연결

상단 그림에서 A와 B, E와 F는 모두 IPv6 라우터이고 **이더넷(Ethernet)**으로 직접 연결되어 있습니다.

- 이 경우 IPv6 데이터그램은 **링크 계층 프레임(link-layer frame)의 페이로드로 탑재**되어 전달됩니다.    
- 즉, “링크 계층 프레임 안에 IPv6 패킷” 구조입니다.

### 2) IPv4 터널을 통한 IPv6 라우터 간 연결

하단 그림에서는 A와 B, E와 F는 IPv6 라우터이지만,  
A–E 구간은 **IPv4 라우터들로 이루어진 네트워크**입니다.

두 IPv6 라우터 사이를 IPv4 네트워크가 가로막고 있기 때문에, IPv6 데이터그램을 직접 전달할 수 없습니다.  
이때 사용되는 기술이 바로 **터널링(tunneling)**입니다.

- IPv6 데이터그램을 **IPv4 데이터그램의 페이로드(payload)**로 캡슐화합니다.    
- 즉, 그림처럼 “IPv4 데이터그램 내부에 IPv6 데이터그램이 들어 있는 형태”가 됩니다.
- 이렇게 하면 IPv4 라우터들도 IPv6 데이터를 문제없이 전달할 수 있습니다.  
    (IPv4 라우터는 내부 내용이 IPv6인지 신경 쓰지 않음)

## 요약

- IPv6 라우터가 직접 연결된 경우: IPv6 패킷은 링크 계층 프레임에 그대로 실려 전달된다.    
- IPv4 네트워크를 통해 IPv6 라우터가 연결되어야 할 경우: **터널링**을 사용하여 IPv6 패킷을 IPv4 패킷 내부에 캡슐화한다.
- 터널링은 “패킷 안에 패킷” 구조로서, IPv6 전환 과정에서 IPv4 기반 네트워크와 공존하기 위한 핵심 기술이다.


## Tunneling

### 번역

### 1) 논리적 관점(logical view)

A, B, E, F는 IPv6 라우터입니다.  
하지만 B–E 구간은 **IPv4 라우터들 위에서 구성된 IPv4 터널**을 통해 연결됩니다.  
즉, 논리적으로는 A → B → E → F로 **IPv6 구간이 연속되어 있는 것처럼 보입니다.**

### 2) 물리적 관점(physical view)

A–B

- A와 B는 직접 IPv6로 연결되어 있으므로 **순수 IPv6 패킷**이 전달됩니다.
    - src: A
    - dest: F

B–C–D–E (IPv4 터널 구간)

- 여기서 실제 네트워크는 IPv4 기반이므로, IPv6 패킷을 그대로 전달할 수 없습니다.
- 따라서 **IPv6 패킷을 IPv4 패킷 내부에 캡슐화하여 운반**합니다.
    - 바깥쪽(IPv4 헤더)의 주소:
        - src: B
        - dest: E

    - 안쪽(IPv6 헤더)의 주소:        
        - src: A
        - dest: F

- 이 구간 전체에서 IPv4 헤더의 주소는 동일하게 유지됩니다.  
    (src=B, dest=E)    

E–F

- 최종적으로 IPv6 영역에 도달하면 다시 **순수 IPv6 패킷 형태로 복원**되어 전달됩니다.

### 핵심 포인트

그림에서 강조하는 부분은 다음과 같습니다:
- **바깥쪽(외부) 패킷의 주소는 터널의 양 끝(B → E).**
- **안쪽(내부) IPv6 패킷의 주소는 실제 통신 엔드포인트(A → F).**

즉, 터널 구간에서는 A·F가 보이지 않고, 오직 B·E의 주소만 외부에 나타납니다.

## 요약

- 터널링에서는 **IPv6 패킷을 그대로 IPv4 패킷 내부에 넣어 전달**한다.    
- 터널 구간에서는 IPv4 헤더(src=B, dest=E)가 사용되며, 내부 IPv6 헤더(src=A, dest=F)는 변경되지 않는다.
- 터널의 양 끝에서 캡슐화/디캡슐화가 이루어져 IPv4 네트워크를 IPv6 패킷이 그대로 통과할 수 있게 한다.


## Generalized Forwarding: match plus action

**복습:** 모든 라우터는 **forwarding table**(flow table이라고도 함)을 가지고 있습니다.

- **“match plus action”** 추상화:  
    패킷 도착 시, 헤더의 특정 비트를 **매칭(match)** 하고, 그 결과에 따라 **특정 동작(action)** 을 수행하는 방식입니다.
- **destination-based forwarding:**  
    목적지 IP 주소를 기준으로 포워딩하는 전통적 방식입니다.
- **generalized forwarding:**  
    목적지 주소뿐 아니라 **다양한 헤더 필드**가 동작을 결정할 수 있습니다.  
    가능한 동작(action)의 범위도 넓어져 다음이 포함될 수 있습니다.
    - drop(버리기)
    - copy(복사)
    - modify(헤더 수정)
    - log packet(기록)

그림에서는 패킷 헤더의 값이 포워딩 테이블의 규칙과 매칭되고, 그 결과 특정 출력 인터페이스 번호(예: 1, 2, 3)로 포워딩되는 과정을 나타냅니다.
## 요약

- 라우터는 도착한 패킷의 특정 헤더 비트를 **매칭**하고, 그에 따라 **정해진 행동**을 수행하는 방식으로 작동한다    
- 기존에는 목적지 IP 주소만 보았지만, 일반화된 포워딩은 다양한 헤더 필드와 다양한 액션을 지원한다.


## Flow table abstraction

- **flow**:  
    링크 계층, 네트워크 계층, 전송 계층의 **헤더 필드 값 조합**으로 정의되는 흐름을 의미합니다.
- **generalized forwarding**:  
    간단한 패킷 처리 규칙들의 집합으로 이루어진 포워딩 방식입니다.
    - **match**:  
        패킷 헤더 필드에서 특정 패턴 값을 매칭합니다.
    - **actions**:  
        매칭된 패킷에 대해 수행하는 동작입니다. 예:  
        drop, forward, modify, 매칭된 패킷을 컨트롤러로 전달(send to controller)
    - **priority**:  
        여러 규칙이 동시에 매칭될 때 우선순위를 이용하여 규칙을 선택합니다.
    - **counters**:  
        매칭된 흐름에 대해 총 바이트 수(#bytes), 총 패킷 수(#packets)를 기록합니다.

그림 설명:  
라우터의 flow table은 “match + action” 규칙을 정의하며, 각 패킷이 어떤 규칙과 매칭되는지에 따라 행동이 결정됩니다.

## 요약

Flow table은 여러 헤더 필드 조합을 기준으로 패킷을 구분하고,  
각 흐름(flow)에 대해 **매칭 규칙 + 동작(action)** 을 정의하여 패킷 처리 방식을 결정하는 구조입니다.  
우선순위와 카운터 기능도 함께 포함됩니다.


# 📘 OpenFlow: Examples — 번역 및 요약

## ■ Destination-based forwarding (목적지 기반 포워딩)

### 번역

- 목적지 IP 주소가 **51.6.0.8**인 모든 IP 데이터그램은 스위치의 **출력 포트 6(port 6)** 으로 전달되어야 합니다.

### 요약

- 패킷의 목적지 IP 주소만 매칭하여 어느 포트로 보낼지 결정하는 규칙을 예시로 보여줌.    

## ■ Firewall 예시

### 1) 목적지 TCP 포트 기반 차단 규칙

#### 번역

- 목적지 TCP 포트가 **22번(ssh)** 인 모든 데이터그램을 **차단(drop)** 합니다.    

#### 요약

- TCP 포트 번호(22)를 기준으로 트래픽을 차단하는 방화벽 규칙.

### 2) 특정 출발지 IP 기반 차단 규칙

#### 번역

- 출발지 IP 주소가 **128.119.1.1**인 모든 데이터그램을 **차단(drop)** 합니다.
   
#### 요약

- 특정 호스트의 모든 트래픽을 차단하는 규칙.

# 📘 OpenFlow: Layer 2 forwarding — 번역 및 요약

## ■ Layer 2 목적지 MAC 기반 포워딩

### 번역

- 목적지 MAC 주소가 **22:A7:23:11:E1:02**인 L2 프레임은 **출력 포트 3(port 3)** 으로 전달되어야 합니다.    

### 요약

- IP가 아니라 MAC 주소를 기준으로 프레임을 포워딩하는 규칙 예시.

# 전체 핵심 정리

1. **OpenFlow 규칙의 기본 구성은 ‘match → action’**    
    - match: 헤더 필드 값(MAC/IP/TCP 등)
    - action: forward, drop, modify 등
2. **어떤 헤더 필드를 매칭할지 선택하여 다양한 정책 구현 가능**
    - Layer 3(IP 기반)
    - Layer 2(MAC 기반)
    - Transport(TCP/UDP 포트 기반)
3. **방화벽·포워딩·트래픽 제어 등의 정책을 일관된 방식으로 정의 가능**


- 이 추상화는 서로 다른 종류의 네트워크 장비를 하나의 공통된 방식으로 통일하여 다룰 수 있도록 해 줍니다.

## Router

- **match:** 가장 긴 목적지 IP 프리픽스(Longest Prefix Match)
- **action:** 해당 링크로 패킷을 포워딩

## Switch

- **match:** 목적지 MAC 주소    
- **action:** 포워드하거나 플러딩

## Firewall

- **match:** IP 주소 및 TCP/UDP 포트 번호    
- **action:** 허용(permit) 또는 차단(deny)

## NAT

- **match:** IP 주소와 포트 번호    
- **action:** 주소 및 포트 번호 재작성(rewrite)
# 요약

이 슬라이드는 OpenFlow가 제공하는 **match + action 모델**이 서로 다른 네트워크 장비(라우터, 스위치, 방화벽, NAT)를 **동일한 구조로 표현할 수 있게 하는 공통 추상화**라는 점을 설명하고 있습니다.

- 라우터는 IP 프리픽스를 기준으로 경로 선택 
- 스위치는 MAC 주소를 기준으로 포워딩
- 방화벽은 주소 및 포트를 기준으로 허용/차단  
- NAT는 주소 및 포트를 기준으로 재작성
이렇게 각 장비가 원래 서로 다른 방식의 동작을 수행함에도, OpenFlow에서는 **모두 match 규칙 + action 규칙**으로 기술될 수 있습니다.


# 🔹 OpenFlow example — 번역 및 설명

### ■ 오른쪽 설명 번역

**“조정된(flow orchestrated) 테이블들은 네트워크 전체 수준(network-wide)의 동작을 만들 수 있다. 예를 들어:**

- **호스트 h5와 h6에서 발생한 데이터그램은 h3 또는 h4로 전달되어야 하며, 그 과정은 s1을 거쳐 s2로 향하는 경로를 통해 이루어진다.”**    

👉 **설명:**  
OpenFlow 컨트롤러가 각 스위치의 _flow table_을 통합적으로 관리하면, 네트워크 전체에 걸쳐 동일한 정책 또는 경로 제어를 실현할 수 있음을 보여주는 사례이다.
# 🔹 각 스위치의 match–action 규칙 번역 및 설명

## ▣ s3의 규칙 (왼쪽 상단)

### **match**
- IP Src = 10.3._._
- IP Dst = 10.2._._

### **action**
- forward(3)

👉 **설명:**  
s3 스위치는 10.3.x.x(즉 h5, h6)에서 오고, 목적지가 10.2.x.x(h3, h4)인 패킷이 들어오면 **포트 3**으로 보낸다.  
즉, h5/h6 → s3 → (포트3) → s1 방향으로 전달된다.
## ▣ s1의 규칙 (왼쪽 하단)

### **match**
- ingress port = 1
- IP Src = 10.3._._
- IP Dst = 10.2._._

### **action**
- forward(4)

👉 **설명:**  
s1 스위치에서 **포트 1(= s3에서 들어오는 포트)**로 들어온, h5/h6에서 온 패킷은 **포트 4 방향(s2 방향)**으로 전송된다.
## ▣ s2의 규칙 (오른쪽 하단)

### 규칙 1
**match**
- ingress port = 2
- IP Dst = 10.2.0.3

**action**
- forward(3)

👉 **설명:**  
목적지가 **h3(10.2.0.3)**인 패킷은 포트 3(h3로 가는 포트)으로 보낸다.
### 규칙 2

**match**
- ingress port = 2
- IP Dst = 10.2.0.4

**action**
- forward(4)

👉 **설명:**  
목적지가 **h4(10.2.0.4)**인 패킷은 포트 4(h4로 가는 포트)로 보낸다.

# 🔹 전체 동작 요약

### 1) h5 또는 h6에서 패킷 송신
- Src: 10.3.x.x
- Dst: 10.2.x.x

### 2) s3에서 매칭
→ s3는 목적지가 10.2.*.*이면 포트 3으로 전송 → s1로 전달

### 3) s1에서 매칭
→ ingress port = 1 (s3에서 옴)  
→ 포트 4로 전송 → s2로 전달

### 4) s2에서 최종 목적지에 따라 분기
- 목적지 10.2.0.3 → 포트3 → h3
- 목적지 10.2.0.4 → 포트4 → h4

# 🔹 핵심 개념 설명

- 이 예제는 **OpenFlow 컨트롤러가 각 스위치의 flow table을 통합적으로 조정하여**  
    네트워크 전체 경로를 하나의 정책처럼 만들 수 있음을 보여준다.    
- 개별 장비는 단순히 _match → action_만 수행하지만,  
    컨트롤러는 이를 조합하여 **네트워크-wide 경로 최적화, 트래픽 엔지니어링, 정책 기반 라우팅** 등을 가능하게 한다.

