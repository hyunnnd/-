
## 📌 Network-layer services and protocols (네트워크 계층 서비스 및 프로토콜)

### 1. 송신 호스트에서 수신 호스트로 세그먼트 전달

- **송신자(sender)**  
    전송 계층에서 만들어진 세그먼트를 **데이터그램(datagram)** 형태로 캡슐화한 뒤 **링크 계층으로 전달**합니다.

- **수신자(receiver)**  
    링크 계층으로부터 수신한 데이터그램에서 세그먼트를 **추출하여 전송 계층 프로토콜에 전달**합니다.    

### 2. 네트워크 계층 프로토콜의 적용 범위

- 네트워크 계층은 **모든 인터넷 장치(every Internet device)** 에 존재합니다.  
    예시: **호스트(host), 라우터(router)**

### 3. 라우터의 역할

- **수신한 모든 IP 데이터그램의 헤더 필드를 검사**합니다.
- **입력 포트에서 받은 데이터그램을 적절한 출력 포트로 전달**하여  
    **종단 간(end-to-end) 경로를 따라 데이터그램이 이동하도록 함**.

## 📌 그림 설명 (간단 해설)

- 모바일 네트워크, 기업 네트워크, 데이터센터 네트워크, 글로벌 ISP 등이 **연결되어 하나의 인터넷 경로를 구성**하고 있습니다.
- 각 라우터는 **network / link / physical 계층**으로 구성되어 있으며  
    패킷을 전달할 때 **상위 계층의 데이터를 해석하지 않고 IP 헤더만 기반으로 전달 결정**을 수행합니다.
- **호스트는 application / transport / network / link / physical 계층을 모두 사용**합니다.

## 💡 핵심 요약

| 구성 요소      | 역할                                |
| ---------- | --------------------------------- |
| Sender     | 세그먼트를 데이터그램으로 캡슐화 후 링크 계층으로 전달    |
| Receiver   | 데이터그램에서 세그먼트를 추출해 전송 계층으로 전달      |
| Router     | IP 헤더 검사, 입력 포트 → 출력 포트로 데이터그램 전달 |
| Network 계층 | 모든 인터넷 장치에 존재하며 IP 기반 전달 수행       |

## ✔ 보충 설명

- 네트워크 계층의 대표 프로토콜은 **IP(Internet Protocol)** 입니다.    
- 라우터는 **IP 주소 기반으로 경로를 결정(route)** 하며, **종단 간 신뢰성 보장은 하지 않습니다**.  
    신뢰성은 전송 계층(TCP 등)이 담당합니다.
- 데이터그램 전달의 목표는 **최선형(best-effort)** 전달이며,  
    **지연·손실이 발생하더라도 재전송을 보장하지 않습니다**.



## 📌 Two key network-layer functions (네트워크 계층의 두 핵심 기능)

### 1) Forwarding (포워딩)

- 라우터의 **입력 링크로 들어온 패킷을 적절한 출력 링크로 이동시키는 과정**입니다.
- 즉, **패킷을 다음 라우터 또는 목적지로 넘기는 동작 자체**를 의미합니다.

### 2) Routing (라우팅)

- 패킷이 **출발지에서 목적지까지 도달하기 위한 전체 경로를 결정하는 과정**입니다.
- **라우팅 알고리즘(routing algorithms)** 을 사용하여 최적 경로를 계산합니다.    

## 🔍 둘의 차이를 이해하는 비유 (여행에 비교)

|개념|여행에 비유|설명|
|---|---|---|
|Forwarding|교차로(인터체인지)에서 길을 선택해 빠져나오는 과정|이미 계획된 경로에 따라 다음 구간으로 이동하는 수행 단계|
|Routing|출발지부터 목적지까지 갈 전체 경로를 사전에 계획하는 과정|어떤 경로로 갈지 결정하는 계획 단계|

## ✔ 핵심 요약

|항목|수행 시점|담당 주체|주요 작동 방식|
|---|---|---|---|
|Forwarding|실시간 패킷 전달 중|라우터|포워딩 테이블을 기반으로 다음 출력 포트 선택|
|Routing|경로 계산 단계|각각의 라우터 + 네트워크 전체|라우팅 알고리즘을 통해 경로 계산 후 라우팅 테이블 구성|


## 💡 추가 설명

- Forwarding과 Routing은 함께 동작하지만 **책임 범위가 다릅니다**.  
    Forwarding은 **“지금 이 패킷을 어디로 보낼까?”**,  
    Routing은 **“전체적으로 어떤 경로가 가장 최적·가장 빠르게 목적지에 도달할까?”** 를 결정합니다.
- Routing의 결과가 **라우팅 테이블을 생성하고 유지**, Forwarding은 **라우팅 테이블을 실제 패킷 전달에 사용**합니다.


## 📌 Network layer: data plane, control plane (네트워크 계층: 데이터 플레인, 컨트롤 플레인)

### 🔹 Data Plane (데이터 플레인)

- **로컬(local), 라우터별 기능**
- 라우터의 **입력 포트로 들어온 데이터그램을 어떤 출력 포트로 전달할지 결정하는 역할**
- 즉, **포워딩(forwarding)** 기능을 수행하는 영역입니다.

> 도착한 패킷 헤더의 값을 기반으로 → 포워딩 테이블을 조회 → 특정 출력 포트로 패킷을 전송

### 🔹 Control Plane (컨트롤 플레인)

- **네트워크 전체 관점(network-wide logic)**    
- 데이터그램이 **출발지에서 목적지까지 네트워크 내 여러 라우터를 어떤 경로로 통과할지 결정**
- 즉, **라우팅(routing)** 기능을 수행하는 영역입니다.

#### 컨트롤 플레인의 두 가지 방식

| 방식                  | 설명                   | 구현 위치     |
| ------------------- | -------------------- | --------- |
| 전통적 라우팅 알고리즘        | 각 라우터가 스스로 라우팅 계산 수행 | 라우터 내부    |
| 소프트웨어 정의 네트워킹 (SDN) | 컨트롤 기능을 서버에 중앙집중화    | 외부(원격) 서버 |

## ✔ 핵심 비교 요약

| 항목    | Data Plane            | Control Plane            |
| ----- | --------------------- | ------------------------ |
| 기능    | 패킷 전달 (포워딩)           | 경로 결정 (라우팅)              |
| 적용 범위 | 개별 라우터 로컬             | 네트워크 전체                  |
| 작동 방식 | 포워딩 테이블 기반으로 출력 포트 선택 | 라우팅 알고리즘 또는 SDN 기반 경로 계산 |
| 시간 특성 | 실시간                   | 비실시간 (계산 후 테이블에 반영)      |

## 💡 추가 설명

- Control Plane이 **라우팅 테이블을 생성·관리**하고, Data Plane은 그 테이블을 기반으로 **실제로 패킷을 전달**합니다.    
- SDN 방식에서는 **제어 기능이 분리되어 중앙 컨트롤러가 경로를 결정**하고, 라우터는 **데이터 전달에만 집중**합니다.
- 이 분리는 대규모 네트워크에서 **트래픽 관리 효율성, 정책 적용, 네트워크 확장성**을 향상시킵니다.


## 📌 Per-router control plane (라우터별 컨트롤 플레인)

### 🔹 개념 설명

- **각 라우터 내부에 라우팅 알고리즘이 존재하며**,  
    이 라우팅 알고리즘들이 서로 **정보를 교환하며 컨트롤 플레인을 구성**합니다.
- 즉, **네트워크 전체 경로를 계산하는 작업을 각 라우터가 분산적으로 수행**하는 방식입니다.

### 🔹 동작 과정 이해

1. 각 라우터는 **라우팅 알고리즘을 실행**합니다.    
2. 라우터끼리는 **라우팅 정보를 서로 교환**합니다. (그림의 빨간 화살표)
3. 이 정보 교환을 통해 **라우팅 테이블이 업데이트**됩니다.
4. 업데이트된 테이블이 **데이터 플레인에 반영**되어 포워딩이 수행됩니다.

### 🔹 구조적 분리

| 영역            | 역할                     | 위치         |
| ------------- | ---------------------- | ---------- |
| Control Plane | 라우팅 계산 및 테이블 생성        | 라우터 내부(상단) |
| Data Plane    | 라우팅 테이블을 바탕으로 실제 패킷 전달 | 라우터 내부(하단) |

### 🔹 그림의 핵심 포인트 요약

- **좌측 패킷 예시**  
    패킷의 헤더 값이 입력되면 → **로컬 포워딩 테이블 조회 → 출력 포트 선택**    
- **각 라우터 상단의 빨간 연결선**  
    라우터들 간 **라우팅 정보 교환 → 컨트롤 플레인 형성**
- **각 라우터 하단의 파란 부분**  
    실제 패킷 전달이 이루어지는 **데이터 플레인**

## ✔ 핵심 요약

| 특징        | Per-router control plane        |
| --------- | ------------------------------- |
| 라우팅 계산 방식 | 라우터 개별적으로 수행 (분산형)              |
| 장점        | 장애 시에도 일부 라우터는 계속 동작 가능, 분산적 확장 |
| 단점        | 관리 어려움, 라우팅 계산 복잡 및 비효율 가능      |
| 대표 기술     | RIP, OSPF, BGP 등 기존 라우팅 프로토콜    |


## 📌 Software-Defined Networking (SDN) control plane

**SDN 컨트롤 플레인**

### 🔹 핵심 개념

- **컨트롤 플레인 기능을 라우터 내부가 아닌 외부(원격) 컨트롤러에 집중시키는 방식**입니다.
- 원격 컨트롤러가 **라우팅 계산을 수행하고**, 그 결과를 라우터에 전달하여 **포워딩 테이블을 설치**합니다.

### 🔹 동작 과정 요약

1. 네트워크 전체의 상태를 SDN 컨트롤러가 수집합니다.    
2. 컨트롤러가 **패킷 경로(라우팅)** 를 통합적으로 계산합니다.
3. 계산된 결과를 각 라우터에 전달하여 **포워딩 테이블을 구성/업데이트**합니다.
4. 라우터는 전달받은 포워딩 테이블을 사용하여 **데이터 플레인에서 실시간 패킷 전달**을 수행합니다.

> 즉, **라우팅 결정은 중앙 서버가 담당하고**, **라우터는 전달(Forwarding) 기능에만 집중합니다.**

### 🔹 구조적 분리

| 영역            | 역할               | 위치              |
| ------------- | ---------------- | --------------- |
| Control Plane | 라우팅 계산 및 정책 적용   | SDN 원격 컨트롤러(중앙) |
| Data Plane    | 포워딩 테이블 기반 패킷 전달 | 개별 라우터 내부       |


### 🔹 그림 이해 포인트

- 상단의 **Remote Controller**  
    → 네트워크 전체 경로를 계획하여 포워딩 테이블을 생성    
- 하단의 **라우터들 (CA 표기)**  
    → 컨트롤러가 내려주는 테이블을 수신하고 데이터 전달만 수행
- 빨간 화살표  
    → 컨트롤러 ↔ 라우터 간 포워딩 규칙 전달

## ✔ SDN의 장점

| 항목        | 설명                             |
| --------- | ------------------------------ |
| 중앙 집중 관리  | 네트워크 전체 정책 및 경로를 컨트롤러에서 일괄 제어  |
| 유연성 및 확장성 | 소프트웨어 업데이트만으로 네트워크 동작 변경 가능    |
| 자동화       | 트래픽 상황에 따라 실시간 라우팅 정책 자동 조정 가능 |

## ✔ SDN의 단점

| 항목           | 설명                                   |
| ------------ | ------------------------------------ |
| 컨트롤러 장애 시 위험 | 단일 장애 지점(Single Point of Failure) 가능 |
| 높은 초기 구축 비용  | 컨트롤러 인프라 구축 및 장비 호환 필요               |

## 💡 Per-router Control Plane과의 비교

| 방식           | Per-router control plane | SDN control plane            |
| ------------ | ------------------------ | ---------------------------- |
| 구조           | 분산형                      | 중앙집중형                        |
| 라우팅 계산 수행 주체 | 각 라우터                    | SDN 컨트롤러                     |
| 라우터의 역할      | 경로 계산 + 전달               | 전달(Forwarding) 전담            |
| 대표 프로토콜/기술   | RIP, OSPF, BGP           | OpenFlow, ONOS, OpenDaylight |


## 📌 Network service model (네트워크 서비스 모델)

### 🔹 핵심 질문

> 송신자에서 수신자로 데이터그램을 운반하는 **채널이 제공할 수 있는 서비스 모델은 무엇인가?**

네트워크 계층은 모든 데이터그램을 그냥 “최선형 전달(best-effort)”로 보내는 것만이 아니라, 특정 서비스 품질(QoS)을 제공하도록 설계될 수도 있습니다.

## 🔸 서비스 모델의 예시

### 1) 개별 데이터그램을 위한 서비스 (individual datagrams)

|서비스 예시|설명|
|---|---|
|guaranteed delivery|데이터그램의 **전달을 보장**|
|guaranteed delivery with less than 40 ms delay|**40ms 이하의 지연을 보장하면서 전달**|

→ 단일 패킷의 도착 여부 및 지연 시간에 초점을 둔 서비스

### 2) 데이터그램 흐름(flow) 전체를 위한 서비스

한 세션 또는 스트림 단위의 패킷 흐름(flow)에 대해 적용되는 서비스

|서비스 예시|설명|
|---|---|
|in-order datagram delivery|패킷을 **전송한 순서대로 도착하도록 보장**|
|guaranteed minimum bandwidth to flow|해당 흐름을 위해 **최소 대역폭을 보장**|
|restrictions on changes in inter-packet spacing|**패킷 간 시간 간격(inter-packet spacing)의 변화를 제한**하여 지터(jitter) 억제|

→ 실시간 스트리밍, 화상회의, 온라인 게임 등 연속적인 패킷 품질이 중요한 서비스에서 필요

## 💡 정리 요약

|서비스 범위|초점|예시|
|---|---|---|
|개별 데이터그램|하나의 패킷의 안전성과 지연|guaranteed delivery, low-delay delivery|
|데이터그램 흐름|스트림 전체의 품질과 일관성|in-order delivery, bandwidth guarantee, jitter control|


## 📌 Network-layer service model (네트워크 계층 서비스 모델)

### 🔹 현재 인터넷의 네트워크 서비스 모델

|Network Architecture|Service Model|QoS 보장 항목|
|---|---|---|
|Internet|best effort|Bandwidth: none / Loss: no / Order: no / Timing: no|

인터넷은 **best effort** 방식을 사용하며, 이는 **전송 품질을 보장하지 않는 모델**을 의미합니다.

### 🔹 Best-effort 서비스 모델의 특징

**보장하지 않는 항목**

1. **데이터그램이 목적지까지 성공적으로 전달된다는 보장 없음**
2. **도착 시간(timing) 또는 순서(order)에 대한 보장 없음**
3. **종단 간(end-to-end) 흐름에 대해 사용 가능한 대역폭 보장 없음**

즉, 네트워크 계층은 패킷을 “가능한 한 전달해 보려는 노력”만 수행하며,  
**지연, 손실, 재전송, 순서 유지, 대역폭 확보 등에 대한 책임을 지지 않습니다.**

### 💡 추가 설명

- TCP, UDP 등의 전송 계층이 **신뢰성 보완 역할을 담당하는 이유**가 바로 이 best-effort 모델 때문입니다.
    - TCP는 손실 복구, 순서 재정렬, 흐름 제어 등을 제공
    - UDP는 보장을 하지 않고 지연을 최소화하는 방향 선택

- 네트워크 계층 자체는 **QoS 지원이 없지만**, 멀티미디어·스트리밍 시대 이후  
    **DiffServ, IntServ, MPLS 등 QoS 기술이 별도로 연구 및 적용**되고 있습니다.    

### ✔ 핵심 요약

|항목|Best-effort 네트워크의 동작 방식|
|---|---|
|패킷 손실|허용됨 (보장하지 않음)|
|전달 순서|보장하지 않음|
|지연 시간|보장하지 않음|
|대역폭|보장하지 않음|
|역할|가능한 한 전달하려고 시도함|


## 📌 Reflections on best-effort service (베스트 에포트 서비스에 대한 고찰)

### 🔹 Best-effort 모델이 성공한 이유

- **메커니즘의 단순성(simplicity of mechanism)**  
    인터넷이 전 세계적으로 빠르게 확산되고 채택될 수 있었던 핵심 요인입니다.  
    설계가 단순하여 확장성·구현 용이성이 매우 뛰어납니다.

- **충분한 대역폭 확보(provisioning of bandwidth)**  
    네트워크 인프라가 발전하면서  
    음성·영상 등 실시간 애플리케이션도 대부분의 시간 동안 충분히 “잘 동작”할 수 있게 되었습니다.
   
- **애플리케이션 계층의 분산 서비스 구조(replication, application-layer distributed services)**  
    데이터센터와 CDN(Content Distribution Network)을  
    사용자 근처에 배치함으로써 가져올 수 있는 성능 향상 덕분에  
    네트워크 계층 QoS 보장이 없어도 서비스 품질을 높일 수 있었습니다.
 
- **탄력적(elastic) 서비스의 혼잡 제어(congestion control)**  
    TCP 기반 서비스와 같은 탄력적 애플리케이션이 혼잡 제어를 수행함으로써  
    네트워크의 과부하 및 붕괴를 방지하고 신뢰성을 높였습니다.
   

### 🔻 결론 문장

> **“best-effort 서비스 모델의 성공을 부정하기는 어렵다.”**  
> → QoS 보장을 제공하지 않지만, 단순성과 확장성, 애플리케이션 계층 기술의 발전으로 인해  
> 인터넷은 오늘날까지도 best-effort 기반으로 안정적으로 유지되고 있습니다.

## 💡 추가 요약 (시험 대비)

| 항목            | 요점                             |
| ------------- | ------------------------------ |
| 핵심 장점         | 단순성, 확장성, 빠른 보급                |
| 어떻게 품질을 보완했는가 | 대역폭 확충, CDN/데이터센터 분산, TCP 혼잡제어 |
| 핵심 메시지        | QoS 없이도 충분히 성공적이었음             |



## 📌 Router architecture overview (라우터 아키텍처 개요)

### 🔹 라우터의 고수준 구조

라우터는 크게 다음 세 부분으로 구성됩니다.

|구성 요소|역할|
|---|---|
|입력 포트 (router input ports)|데이터그램 수신, 헤더 검사, 포워딩 테이블 조회 준비|
|스위칭 패브릭 (high-speed switching fabric)|입력 포트에서 출력 포트로 패킷을 고속으로 전달|
|출력 포트 (router output ports)|큐잉, 스케줄링, 패킷 전송|

### 🔹 Control Plane vs Data Plane

|Plane|역할|위치|동작 속도|
|---|---|---|---|
|Control Plane|라우팅 및 관리 소프트웨어 실행|Routing Processor|밀리초(ms) 시간 단위|
|Data Plane|실제 패킷 포워딩 수행|입·출력 포트 하드웨어|나노초(ns) 시간 단위|

### ✔ Routing Processor (라우팅 프로세서)

- 라우팅 알고리즘, 라우팅 테이블 유지·관리, 네트워크 관리 기능 수행
- 새로운 경로가 학습되면 포워딩 테이블을 업데이트하여 데이터 플레인에 반영

### ✔ High-speed Switching Fabric (고속 스위칭 패브릭)

- 입력 포트에서 출력 포트로 **패킷을 고속으로 연결해 전달**
- 라우터 성능을 좌우하는 핵심 하드웨어


### 🔍 구조를 한 줄로 이해하면

> Control Plane이 **경로를 결정하고**, Data Plane이 **그 경로에 따라 매우 빠르게 패킷을 전달**함

## 핵심 요약

|항목|요점|
|---|---|
|Control Plane|라우팅 계산 및 관리 수행, 느리지만 두뇌 역할|
|Data Plane|패킷 포워딩 처리, 매우 빠른 하드웨어 동작|
|스위칭 패브릭|입력 포트 → 출력 포트 연결|
|시간 단위|Control Plane: ms / Data Plane: ns|

## 📌 Input port functions (입력 포트 기능)

### 🔹 입력 포트 내부 구성 요소

입력 포트는 스위칭 패브릭으로 패킷을 전달하기 전에 다음 단계를 수행합니다.

|단계|설명|관련 계층|
|---|---|---|
|line termination|비트 단위로 신호 수신|물리 계층 (physical layer)|
|link layer protocol (receive)|링크 계층 프레임 처리 (예: Ethernet)|링크 계층 (link layer)|
|lookup, forwarding, queueing|헤더 기반 출력 포트 조회, 큐에 적재 후 전송|네트워크 계층 데이터 플레인|


### 🔹 Decentralized switching (분산 스위칭)

- 입력 포트가 **포워딩 테이블을 자체적으로 보유**하고 있어  
    **헤더 값 기반으로 적절한 출력 포트를 즉시 조회**합니다.
- 즉, **각 입력 포트가 독립적으로 lookup + action 수행**합니다.
- 이 설계의 목적은:
    > 입력 포트에서의 처리 속도를 **line speed(회선 속도)** 에 맞출 수 있도록 하기 위함입니다.

### 🔹 Input port queueing (입력 포트 큐잉)

- 데이터그램 도착 속도가 스위칭 패브릭의 처리 속도보다 빠를 경우  
    입력 포트 내부 큐에 패킷을 저장합니다.    
- 큐가 과도하게 증가할 경우 **패킷 지연 또는 드롭**이 발생할 수 있습니다.

## ✔ 핵심 요약

| 핵심 개념    | 설명                                        |
| -------- | ----------------------------------------- |
| 입력 포트 역할 | 패킷을 수신, 링크 계층 처리, 헤더 기반 출력 포트 조회, 큐잉 수행   |
| 분산 스위칭   | 입력 포트가 자체적으로 lookup 수행 (“match + action”) |
| 목표       | 전체 처리 속도를 line speed로 유지                  |
| 큐잉 이유    | 패킷 도착 속도가 스위칭 패브릭 처리 속도를 초과할 때            |

### 🔹 Destination-based forwarding (목적지 기반 포워딩)

- **목적지 IP 주소만**을 이용하여 포워딩 결정을 수행하는 방식입니다.
- 현재 인터넷에서 사용되는 **전통적·표준적인 포워딩 방식**입니다.
### 🔹 Generalized forwarding (일반화된 포워딩)

- **헤더의 다양한 필드 값 조합**을 기반으로 포워딩 결정을 수행하는 방식입니다.

## 📌 Destination-based forwarding (목적지 기반 포워딩)

### 🔹 Forwarding table 개념

라우터는 **도착지 IP 주소의 비트 패턴 범위**에 따라 **출력 포트를 선택**합니다.

`Destination Address Range  →  Link Interface`

→ 즉, 특정 IP 주소가 어느 범위에 속하는지 확인하여, 해당 범위에 매핑된 인터페이스로 포워딩합니다.

## 📌 예시 ① (정확히 나누어지는 주소 범위)

슬라이드 1은 목적지 주소 범위가 **깔끔하게 연속된 구간으로 분할**되는 경우입니다.

|Destination Address Range|Link Interface|
|---|---|
|11001000 00010111 00010000 00000000 ~ 11001000 00010111 00010111 11111111|0|
|11001000 00010111 00011000 00000000 ~ 11001000 00010111 00011000 11111111|1|
|11001000 00010111 00010001 00000000 ~ 11001000 00010111 00011111 11111111|2|
|Otherwise|3|

→ 목적지 주소가 어떤 범위에 속하는지 확인 → 해당 범위의 인터페이스로 전달

## 📌 예시 ② (범위가 깔끔하게 안 나누어지는 경우)

슬라이드 2는 **주소 범위가 규칙적으로 나누어지지 않을 때**의 forwarding table 예시입니다.

중간 두 항목에 분홍색으로 표시된 부분이  
`00000 100` ~ `00000 111` 처럼 **애매하게 끊기는 작은 주소 구간**을 의미합니다.

이처럼 목적지 범위가 규칙적이지 않은 경우,

- 더 많은 엔트리가 필요해지고
- 테이블 크기는 증가하며
- 검색 비용도 증가합니다.
   
## ❗ 중요한 질문

> 주소 범위가 깔끔하게 나누어지지 않으면 어떻게 되는가?
➡ Forwarding table이 매우 커지고 비효율적이 됩니다.

## 💡 이 문제를 해결하기 위해 등장한 기술

범위 기반 forwarding 테이블의 비효율을 줄이기 위해  
**Longest Prefix Matching (LPM, 최장 접두사 매칭)** 기법이 도입되었습니다.

> 주소 범위를 나열하는 대신 → **공통 접두사(prefix)** 를 사용하여 테이블 엔트리를 최소화

예:

`11001000 00010111 0001xxxx xxxxxxxx  →  output interface #1`

→ CIDR 방식의 IP 주소 체계와 현재 인터넷 라우팅 방식의 기본 원리

## ✔ 핵심 요약

| 항목                           | 내용                                    |
| ---------------------------- | ------------------------------------- |
| Destination-based forwarding | 도착지 주소 기반으로 출력 포트 결정                  |
| 단순한 경우                       | 주소 범위가 깔끔하게 나뉘어 forwarding table이 효율적 |
| 복잡한 경우                       | 엔트리가 비대해지고 검색이 비효율적                   |
| 근본 해결책                       | **Longest Prefix Matching (CIDR 기반)** |


## 📌 Longest Prefix Matching (최장 접두사 매칭)

### 🔹 개념 정의

라우터가 목적지 IP 주소를 기반으로 포워딩 테이블을 조회할 때,  
**가장 길게 일치하는(prefix 길이가 가장 긴) 주소 접두사 항목을 선택하여** 출력 포트를 결정하는 방법입니다.

> 단순히 “처음으로 일치하는 항목”을 선택하는 것이 아니라,  
> **가장 많은 비트가 연속적으로 일치하는 항목을 선택**합니다.

### 🔹 동작 방식 예시 (슬라이드 테이블)

|Destination Address Prefix|Link Interface|
|---|---|
|11001000 00010111 000010*** ********|0|
|11001000 00010111 000011000 ********|1|
|11001000 00010111 000011*** ********|2|
|otherwise|3|

### 🔸 핵심 포인트

- 목적지 주소가 여러 항목과 매칭될 수 있음
- 이 경우 **일치 길이가 가장 긴(prefix가 가장 구체적인) 항목이 선택됨**
- 따라서 테이블 설계 시 **보다 구체적인 주소가 상단에 있을 필요는 없음**  
    → longest prefix rule이 자동으로 선택해 주기 때문입니다.

## 🔍 예시 분석

| 목적지 주소                               | 어떤 인터페이스로 포워딩되는가? |
| ------------------------------------ | ----------------- |
| 11001000 00010111 000010110 10100001 | ?                 |
| 11001000 00010111 000011000 10101010 | ?                 |

### 분석 방법

각 주소의 앞부분을 테이블의 prefix와 비교 →  
가장 긴 bit-prefix가 일치하는 항목을 선택

### 🔺 첫 번째 주소

`11001000 00010111 000010110 10100001`

- 첫 번째 prefix: `11001000 00010111 000010***` ⬅ **일치**    
- 두 번째 prefix: `11001000 00010111 000011000` ⬅ 일부만 일치 (0/1 전환에서 불일치)
- 세 번째 prefix: `11001000 00010111 000011***` ⬅ 일부만 일치

➡ 가장 긴 일치(prefix 길이가 가장 긴 항목) = **첫 번째 항목 → 인터페이스 0**

## 🔺 두 번째 주소

`11001000 00010111 000011000 10101010`

- 두 번째 prefix: `11001000 00010111 000011000` ⬅ **완전히 일치**   
- 세 번째 prefix: `11001000 00010111 000011***` ⬅ 일치하지만 접두사 길이가 더 짧음
- 첫 번째 prefix: 앞부분이 일치하지 않음

➡ 가장 긴 일치(prefix 길이가 가장 긴 항목) = **두 번째 항목 → 인터페이스 1**

## ✔ 최종 요약

| 목적지 주소                               | 선택된 인터페이스       |
| ------------------------------------ | --------------- |
| 11001000 00010111 000010110 10100001 | **Interface 0** |
| 11001000 00010111 000011000 10101010 | **Interface 1** |

## 💡 결론

Longest Prefix Matching의 목적은 다음과 같습니다.

- forwarding table을 **작게** 유지하면서도    
- 다양한 목적지 범위를 **정확하게 구분**하고
- 가장 **특화된(구체적인) 경로를 선택**하도록 보장

따라서 오늘날 인터넷 라우터는 모두 **Longest Prefix Matching + CIDR 주소 체계**를 기반으로 동작합니다.


## 📌 Longest prefix matching — 번역

- 주소 지정(addressing)을 공부할 때, 왜 longest prefix matching이 사용되는지 곧 보게 될 것입니다.
- longest prefix matching은 보통 **삼진 내용 주소 지정 메모리(TCAM, Ternary Content Addressable Memories)** 를 이용하여 수행됩니다.
    - **content addressable**: 주소를 TCAM에 제시하면, 테이블의 크기와 무관하게 **한 클록 사이클 내에** 해당 주소를 검색합니다.
    - Cisco Catalyst: TCAM 안에 약 **100만 개(1M) 라우팅 테이블 엔트리** 저장 가능


## 📌 Switching fabrics — 번역

- 입력 링크에서 적절한 출력 링크로 패킷을 전달한다.
- **switching rate**: 패킷이 입력에서 출력으로 전송될 수 있는 속도
    - 입력/출력 회선 속도의 배수로 측정되는 경우가 많다.
    - N개의 입력이 있을 때, 스위칭 속도가 회선 속도의 **N배가 되는 것이 바람직하다.**

그림 설명:

- 왼쪽에는 **N개의 입력 포트**, 오른쪽에는 **N개의 출력 포트**가 존재하며,  
    가운데의 **고속 스위칭 패브릭**이 입력 포트에서 출력 포트로 패킷을 전달한다.
- 이상적으로는 스위칭 속도가 **NR (회선 속도 × N)** 이 되는 것이 목표이다.


## 📌 Switching fabrics (스위칭 패브릭)

### 🔹 기능

- 입력 링크로 들어온 패킷을 **적절한 출력 링크로 전송**하는 하드웨어 구조를 의미합니다.

### 🔹 Switching rate (스위칭 속도)

- 패킷이 입력에서 출력으로 **전송될 수 있는 속도**를 의미합니다.
- 일반적으로 **입·출력 회선 속도의 배수**로 표현됩니다.
- 입력 포트가 **N개**라면, **스위칭 속도가 회선 속도의 N배가 되는 것이 이상적**입니다.  
    → 모든 입력에서 동시에 패킷이 들어오더라도 병목 없이 전달할 수 있기 때문입니다.

## 🔹 스위칭 패브릭의 세 가지 주요 구조

| 유형                                  | 개념                                           | 장점             | 단점                                |
| ----------------------------------- | -------------------------------------------- | -------------- | --------------------------------- |
| Memory (메모리 기반)                     | CPU가 입력 포트에서 패킷을 읽어 메모리에 저장한 뒤 출력 포트로 보내는 방식 | 가장 단순함         | CPU 성능 한계로 병렬 처리 불가 → 속도 낮음       |
| Bus (버스 기반)                         | 모든 포트가 공유하는 버스를 통해 입력 → 출력으로 패킷 전달           | 구현이 쉽고 확장 용이   | 한 번에 한 패킷만 버스를 사용할 수 있어 충돌·대역폭 제한 |
| Interconnection network (상호연결 네트워크) | 여러 스위치·경로를 이용하여 입력과 출력을 다중 연결                | 높은 병렬성 및 고속 처리 | 구조가 복잡하며 비용이 높음                   |

### 🔍 핵심 비교 요약

| 속도 | 메모리 < 버스 < 상호연결 네트워크 |  
| 병렬성 | 메모리: 없음 → 버스: 제한적 → 상호연결 네트워크: 높음 |  
| 실제 고성능 라우터 | 대부분 **상호연결 네트워크 방식** 사용 |

### ✔ 한 문장 요약

> 스위칭 패브릭은 입력 포트의 패킷을 출력 포트로 전달하는 라우터 내부의 핵심 하드웨어이며, 성능은 **메모리 방식 → 버스 방식 → 상호연결 네트워크 방식** 순으로 향상됩니다.


## 📌 Switching via memory — 번역

**first generation routers:**

- 전통적인 컴퓨터에서 CPU가 스위칭을 직접 제어하는 방식
- 패킷이 시스템 메모리로 복사됨
- 메모리 대역폭에 의해 속도가 제한됨 (각 데이터그램당 버스를 두 번 횡단해야 함)

그림 설명:  
입력 포트(예: Ethernet) → **시스템 버스**를 통해 패킷을 **메모리**에 복사 → 다시 시스템 버스를 통해 **출력 포트**로 복사


## 📌 Switching via a bus — 번역

- 공유 버스를 통해 **입력 포트 메모리에서 출력 포트 메모리로** 데이터그램을 전송한다.
- **bus contention**: 버스 대역폭으로 인해 스위칭 속도가 제한된다.
- 32 Gbps 버스를 사용하는 Cisco 6500 장비는 액세스 라우터 용도로는 충분한 속도를 제공한다.


## 📌 Switching via interconnection network — 번역

- 크로스바(Crossbar), 클로스 네트워크(Clos networks), 그리고 기타 상호연결(interconnection) 네트워크들은  
    원래 다중 프로세서(multiprocessor) 환경에서 프로세서들을 연결하기 위해 개발되었다.

- **multistage switch**: 여러 단계의 소형 스위치를 조합하여 구성된 **n×n 스위치**    
- **병렬성(parallelism) 활용:**
    - 데이터그램을 진입 시 고정 길이 셀로 분할한다.
    - 셀 단위로 스위칭 패브릭을 통과시키고, 출구에서 다시 데이터그램으로 재조립한다.


## 📌 Input port queuing — 번역

- 스위칭 패브릭이 **입력 포트들의 합산 처리 속도보다 느린 경우**,  
    → 입력 큐에서 대기가 발생할 수 있다.
    - 입력 버퍼 오버플로우로 인해 **큐잉 지연 및 패킷 손실**이 발생할 수 있다.

- **Head-of-the-Line (HOL) blocking**:  
    큐의 가장 앞에 있는 데이터그램 때문에  
    뒤에 있는 다른 데이터그램들이 **앞으로 이동하지 못하는 현상**    

### 그림 설명 (좌측)

- 출력 포트 경쟁(output port contention) 상황에서는  
    하나의 빨간 데이터그램만 전송될 수 있다.    
- 아래 줄의 빨간 데이터그램은 **차단(blocked)** 되어 전달되지 못한다.

### 그림 설명 (우측)

- 한 패킷 시간이 지나면 초록 패킷이 스위칭을 시도하지만,  
    앞줄의 패킷 때문에 **HOL 블로킹을 경험**하게 된다.


## 📌 Output port queueing — 번역

- **패킷 스위치 패브릭의 전송 속도**가 링크의 전송 속도보다 빠를 경우, **출력 포트에서 큐잉이 발생할 수 있습니다.**
- **버퍼링(buffering)**은 데이터그램이 패브릭에서 링크로 전달되는 속도보다 더 빠르게 도착할 때 필요합니다.
    - **Drop policy**: 사용 가능한 버퍼가 없을 때 **어떤 데이터그램을 삭제할지** 결정하는 정책입니다.

- **Scheduling discipline**은 **전송을 위해 큐에 저장된 데이터그램들 중 어떤 것을 먼저 보낼지** 결정하는 방식입니다.    

오른쪽 설명:

- **혼잡(congestion)과 버퍼 부족으로 인해 데이터그램이 손실될 수 있습니다.**
- **우선순위 스케줄링(priority scheduling)**은 **어떤 트래픽이 더 높은 성능을 보장받는가**를 결정하며, **네트워크 중립성 문제와도 연관됩니다.**


## 📌 Output port queuing (출력 포트 대기열)

### 🔹 슬라이드 번역

- 스위치 패브릭을 통해 도착하는 패킷의 속도가 출력 링크 전송 속도보다 빠르면 **버퍼링(buffering)** 이 필요함.
- **큐잉 지연(queueing delay)** 과 **출력 버퍼 오버플로우로 인한 손실(loss)** 이 발생할 수 있음


### 🔹 설명

스위치 내부에서 패킷이 출력 포트로 몰릴 때, 출력 링크 속도(R)보다 빠르게 패브릭을 거쳐 패킷이 도달하면 출력 포트는 즉시 처리할 수 없음 → 남는 패킷들은 **출력 버퍼(Output buffer)** 에 저장됨.

버퍼가 꽉 차면:

- 새로 들어온 패킷을 버릴지 결정해야 함 → **Drop Policy** 필요    
- 어떤 패킷을 먼저 전송할지 결정 → **Scheduling Discipline** 필요

### 🔹 주요 문제

| 문제                     | 설명                      |
| ---------------------- | ----------------------- |
| Congestion (혼잡)        | 패브릭 → 출력 포트로 패킷이 몰리면 발생 |
| Packet Loss (패킷 손실)    | 버퍼가 꽉 찼을 때 Drop         |
| Queueing Delay (대기 지연) | 출력 링크에 보내기까지 대기 발생      |

### 🔹 출력 포트 큐잉 과정 흐름

1. 시점 t: 여러 입력 포트 → 동일한 출력 포트로 패킷 전달 중    
2. 출력 포트의 한 번 전송 가능한 속도(R)를 초과
3. 초과한 패킷은 **버퍼에 대기**
4. 시간 경과 후 순서대로 전송되지만 지연 발생 가능
5. 버퍼 부족 시 일부 패킷 Drop


# 📘 Buffer Management

## 📌 번역

### **Buffer Management**

네트워크 장비 내부에서는 패킷이 스위치 패브릭을 통해 들어오면, 먼저 **데이터그램 버퍼(queueing scheduling)** 에 저장된다. 이후 **링크 계층 프로토콜(send)** 을 거쳐 **라인 종단(line termination)** 을 통해 전송된다.

### **Abstraction: queue**

패킷이 도착하면 큐(대기 구역)에 저장되고, 링크(서버)에 의해 순차적으로 처리되어 전송된다.

## **Buffer management:**

### **1. Drop(삭제)**

버퍼가 가득 찼을 때 어떤 패킷을 버릴지 결정하는 메커니즘이다.

- **Tail drop**: 도착한 새 패킷을 즉시 버림
- **Priority drop**: 우선순위에 따라 패킷을 선택적으로 제거함

### **2. Marking(마킹)**

혼잡을 보내는 쪽에 알리기 위해 특정 패킷에 표시를 추가함  
– 사용 예: **ECN**, **RED**

# 📌 요약

- **버퍼 관리(Buffer Management)** 는 스위치 내부에서 패킷을 저장하고 처리하는 과정에서 **어떤 패킷을 버릴지(drop)**, **어떤 패킷을 혼잡 표시(marking)** 할지 결정하는 기술이다.
- **Drop 방식**에는 도착 패킷을 바로 버리는 _tail drop_, 우선순위 기반 제거인 _priority drop_이 있다.
- **Marking 방식**은 네트워크 혼잡을 알리기 위해 패킷에 표시를 하고, ECN·RED 같은 혼잡 제어 메커니즘에서 사용된다.


# 📘 Packet Scheduling: FCFS

### **Packet scheduling**

링크에서 다음으로 어떤 패킷을 전송할지 결정하는 방식이다.  
대표적인 스케줄링 방식은 다음과 같다.

- **first come, first served**
- **priority**
- **round robin**
- **weighted fair queueing**

### **Abstraction: queue**

패킷이 도착하면 큐(대기구역)에 저장되고, 링크(서버)에 의해 순서대로 전송된다.

### **FCFS (First Come, First Served)**

도착한 순서대로 패킷을 출력 포트로 전송하는 방식이다.
- **FIFO(First-In-First-Out)** 로도 불린다.
- 실세계 예: 은행 대기줄, 주차장 입구 순번, 티켓 줄 등

# 📌 요약

- **패킷 스케줄링**은 링크에서 어떤 패킷을 먼저 보낼지 결정하는 과정이다.    
- 대표 방식: FCFS, 우선순위(priority), 라운드 로빈, WFQ 등
- **FCFS(FIFO)** 는 패킷이 들어온 순서대로 처리하는 가장 단순한 방식이다.
- 실생활에서도 흔히 볼 수 있는 "선착순" 처리 방식과 동일하다.


# 📘 Scheduling Policies: Priority

## 📌 번역

### **Priority scheduling**

- 도착하는 트래픽은 우선순위(class)에 따라 분류되고, 각 클래스별 큐에 저장된다.
    - 분류에는 헤더의 어떤 필드라도 사용할 수 있다.

- 전송 시에는 **버퍼에 패킷이 존재하는 가장 높은 우선순위 큐**에서 먼저 선택하여 보낸다.    
    - 같은 우선순위 클래스 내부에서는 **FCFS 방식**으로 처리된다.


## 📌 요약

- **우선순위 스케줄링(priority scheduling)** 은 패킷을 **등급(class)** 으로 나누어 큐에 저장하고,  
    **우선순위가 가장 높은 큐부터 패킷을 전송**하는 방식이다.    
- 각 클래스 내부에서는 FCFS처럼 선착순 처리한다.
- 장점: 긴급 트래픽(예: 음성, 제어 신호 등)을 빠르게 전송할 수 있음
- 단점: 낮은 우선순위 트래픽이 계속 밀려 **기아(starvation)** 가 발생할 수 있음



# 📘 Scheduling Policies: Round Robin

## 📌 번역

### **Round Robin (RR) scheduling**

- 도착한 트래픽은 우선순위 클래스별로 분류되어 각각의 큐에 저장된다.
    - 분류에는 헤더의 어떤 필드라도 사용할 수 있다.

- 서버는 **순환적으로(cyclically)** 각 클래스 큐를 반복적으로 스캔하며,  
    **각 클래스에서 하나의 패킷이 존재하면 1개씩 번갈아가며 전송**한다.    

## 📌 요약

- **라운드 로빈(RR)** 은 여러 클래스가 있을 때 **각 클래스에 공평하게 서비스**를 제공하기 위해  
    한 클래스에서 **한 개씩** 패킷을 꺼내 전송하는 방식이다.    
- 모든 클래스에 균등한 기회를 주므로, 단일 클래스가 링크를 독점할 수 없다.
- 단점: 패킷 크기가 다르면 공평성이 왜곡될 수 있음 → **WFQ가 등장하는 이유**


# 📘 Scheduling Policies: Weighted Fair Queueing

## 📌 번역

### **Weighted Fair Queueing (WFQ)**

- WFQ는 **라운드 로빈(RR)의 일반화된 형태**이다.
- 각 클래스 iii 는 **가중치 wiw_iwi​** 를 가지며,  
    한 사이클에서 **가중치 비율만큼 서비스량**을 배정받는다:

w_i/∑_j w_j​​

- 이를 통해 **트래픽 클래스별 최소 대역폭(minimum bandwidth)** 을 보장할 수 있다.

## 📌 요약

- **WFQ**는 단순한 라운드 로빈과 달리,  
    **클래스마다 서로 다른 비중(가중치)** 을 부여하여 서비스 비율을 조절하는 방식이다.
- 각 클래스는 가중치에 비례한 양의 패킷이 서비스되므로,  
    **대역폭 할당을 정교하게 제어**할 수 있다.
- 장점: 서비스 품질(QoS) 보장, 클래스별 최소 대역폭 확보
- RR보다 공평하며, Priority Queue보다 starvation 문제가 없다


# 📘 IP Datagram Format

## 📌 번역

### **IP 헤더 필드 설명**

- **version**  
    IP 프로토콜 버전 번호(IPv4/IPv6).
- **header length (IHL)**  
    헤더 길이(바이트 단위).
- **type of service (ToS)**  
    패킷 우선순위 관련 필드.
    - DiffServ(비트 0~5)
    - ECN(비트 6~7)
- **total length**  
    전체 IP 데이터그램 길이(바이트).  
    최대 약 64KB, 일반적으로 1500바이트 이하(MTU).
- **16-bit identifier, flags, fragment offset**  
    단편화(fragmentation) 및 재조립(reassembly)에 사용됨.
- **TTL (Time To Live)**  
    남은 최대 홉 수. 각 라우터를 지날 때마다 1씩 감소.
- **upper layer protocol**  
    상위 계층 프로토콜(TCP, UDP 등)을 나타냄.
- **header checksum**  
    IP 헤더에 대한 오류 검출용 체크섬.
- **source IP address**  
    32비트 출발지 IP 주소.
- **destination IP address**  
    32비트 목적지 IP 주소.
- **options** (있을 경우)  
    예: 타임스탬프, 경로 기록 등.
- **payload data**  
    가변 길이 데이터. 보통 TCP/UDP 세그먼트가 포함됨.

### **Overhead**

- TCP 헤더: 20 bytes    
- IP 헤더: 20 bytes  
    → TCP/IP 기본 오버헤드 = **40 bytes + 애플리케이션 계층 오버헤드**
# 📌 요약

- IP 데이터그램은 **고정된 헤더 부분 + 가변 길이 페이로드**로 구성된다.    
- 주요 기능: **라우팅, 단편화, 오류 검출, QoS 정보 전달**
- 헤더는 출발지·목적지 주소, TTL, 프로토콜 정보, 단편화 정보 등을 포함한다.
- TCP/IP 스택에서 최소 **40바이트의 헤더 오버헤드**가 발생한다.


# 📘 IP Fragmentation / Reassembly

## 📌 번역

### **IP 단편화(fragmentation)**

- 네트워크 링크는 **MTU(Maximum Transfer Unit)** 를 가지며, 이는 링크 계층에서 전송할 수 있는 최대 프레임 크기이다.
    - 링크 종류마다 MTU 값이 다르다.

- 큰 크기의 IP 데이터그램은 네트워크 내부에서 **여러 조각(fragment)** 으로 분할된다.    
    - 하나의 데이터그램이 여러 개의 작은 데이터그램으로 나뉨.

- 단편화된 여러 조각은 **목적지에서만(reassembly)** 다시 원래 데이터그램으로 재조립된다.    
- IP 헤더의 특정 비트(Identifier, Flags, Fragment offset)가  
    조각을 식별하고 순서를 재구성하는 데 사용된다.

## 📌 요약

- MTU 제한 때문에 큰 IP 데이터그램은 네트워크 경로 중간에서 **강제 단편화**될 수 있다.    
- 단편화는 **라우터에서 발생**, 재조립은 **목적지에서만 수행**된다.
- IP 헤더는 조각들의 순서와 위치를 표시하여 재조립이 가능하도록 만든다.
- 단편화는 성능 저하 및 패킷 손실 확률 증가를 유발하므로 실제 네트워크에서는 주로 **Path MTU Discovery(PMTUD)** 를 사용하여 회피한다.


# 📘 IP Fragmentation/Reassembly – Example

## 📌 번역

### **예제 조건**

- 원래 IP 데이터그램 크기: **4000 bytes**
- MTU: **1500 bytes**

### **단편화 과정**

- IP 헤더가 20 bytes 이므로,  
    각 fragment의 **데이터(payload)** 는  
    **1500 − 20 = 1480 bytes**까지 담을 수 있다.
- 데이터그램은 아래와 같이 3개의 조각으로 분할된다.
1. **첫 번째 fragment**
- length = 1500
- fragflag = 1 (더 많은 fragment가 있음)
- offset = 0

2. **두 번째 fragment**
- length = 1500
- fragflag = 1
- offset = 1480 / 8 = 185

3. **세 번째 fragment**
- 남은 데이터: 4000 − (1480 × 2) = 1040 bytes
- length = 1040 + 20 = 1060 (헤더 포함)
- fragflag = 0 (마지막 fragment)
- offset = (1480 × 2) / 8 = 370

## 📌 요약

- MTU(1500 bytes)를 넘는 4000-byte 데이터그램은 **3개의 fragment**로 나뉜다.    
- 각 fragment는 최대 **1480 bytes의 데이터**를 가진다(헤더 20 bytes 제외).
- offset은 항상 **8-byte 단위**로 계산된다.
- 마지막 fragment는 **fragflag = 0**, 이전 fragment들은 **fragflag = 1**이다.

# 📘 IP Addressing: Introduction

## 📌 번역

### **IP address**
- IP 주소는 **32비트 식별자**이며, 각 호스트(host) 또는 라우터(router)의 **인터페이스(interface)** 에 할당된다.

### **interface**
- 인터페이스는 **호스트/라우터와 물리적 링크를 연결하는 접점**이다.
- 라우터는 보통 **여러 개의 인터페이스**를 가진다.
- 일반적인 호스트(PC, 스마트폰 등)는 **1~2개의 인터페이스**만 가진다.  
    예: 유선 Ethernet, 무선 Wi-Fi(802.11)
### **dotted-decimal IP notation**

예:
- **223.1.1.1** → 11011111 00000001 00000001 00000001  
    (각 8비트 = 1옥텟, 총 32비트)

## 📌 요약

- IP 주소는 **32비트로 구성된 장치의 논리적 식별자**이다.
- 실제로는 ‘장치 전체’가 아니라 **인터페이스마다 각각 IP 주소를 부여**한다.  
    → 하나의 라우터가 여러 IP를 가지는 이유.
- 호스트는 보통 하나의 인터페이스(Ethernet 또는 Wi-Fi)를 사용한다.    
- IP 주소는 **점-십진 표기(dotted decimal)** 로 작성되며, 이는 32비트 값을 옥텟 단위로 나눈 표현이다.

# 📘 IP Addressing: Introduction (Interfaces)

## 📌 번역

### Q: 인터페이스들은 실제로 어떻게 연결되는가?

A: 이 내용은 **6장**에서 배울 예정이다.

- **유선 연결(wired Ethernet)**  
    → 이더넷 스위치(Ethernet switch)를 통해 여러 Ethernet 인터페이스가 연결된다.    
- **무선 연결(wireless WiFi)**  
    → WiFi 베이스 스테이션(무선 AP)을 통해 WiFi 인터페이스들이 연결된다.

### For now

- 지금은 “라우터 없이 인터페이스끼리 어떻게 연결되는지”에 대해 걱정할 필요는 없다.

## 📌 요약

- IP 주소는 인터페이스에 붙지만, **인터페이스들이 실제로 어떻게 물리적으로 연결되는지**는 더 뒷부분(6장)에서 다룬다.    
- 유선 장비는 **스위치**, 무선 장비는 **WiFi AP**를 통해 인터페이스들이 연결된다.
- 현재 단계에서는 단순히 “인터페이스는 어떤 방식으로든 연결되어 있다” 정도만 알고 있으면 충분하다.


# 📘 Subnets

## 📌 번역 (1) — What’s a subnet?

### **What’s a subnet?**

- 서브넷(subnet)은 **라우터를 거치지 않고 물리적으로 서로 도달 가능한** 장치 인터페이스들의 집합이다.
### **IP addresses have structure**

- **subnet part**: 같은 서브넷에 속한 장치들은 IP 주소의 **상위 비트(high-order bits)** 를 공유한다.
- **host part**: 나머지 **하위 비트(low-order bits)** 는 같은 서브넷 내의 개별 장치를 구분한다.

그림의 예는 총 **3개의 서브넷**으로 구성된 네트워크이다.

## 📌 번역 (2) — How to define subnets

### **Recipe for defining subnets**

- 각 인터페이스를 호스트나 라우터로부터 분리하여 **유사한 인터페이스들의 고립된 네트워크 섬(섬 형태의 그룹)** 을 만든다.
- 이러한 **고립된 네트워크 하나가 서브넷(subnet)** 이다.

### **서브넷 예 (CIDR 표기)**

- subnet **223.1.1.0/24**
- subnet **223.1.2.0/24**
- subnet **223.1.3.0/24**

### **Subnet mask**
- `/24` = 상위 24비트가 서브넷 부분
- 나머지 8비트는 host part

# 📌 요약

- **서브넷(subnet)** 은 라우터를 거치지 않고 도달 가능한 장치 인터페이스들의 집합이다.    
- IP 주소는 **subnet part(상위 비트)** + **host part(하위 비트)** 로 구성된다.
- CIDR 표기 `/24`는 상위 24비트가 네트워크 주소임을 의미한다.
- 서브넷을 정의하는 과정은 네트워크를 여러 “고립된 섬”으로 나누는 것과 같다.
- 위 그림의 네트워크는 **/24로 구성된 3개의 서브넷**(223.1.1.0/24, 223.1.2.0/24, 223.1.3.0/24)으로 이루어져 있다.


# 📘 IP Addressing: CIDR

## 📌 번역

### **CIDR (Classless InterDomain Routing)**

- “사이더(cider)”로 발음된다.
- 서브넷 부분(subnet part)의 길이를 **임의로 설정할 수 있는** 주소 체계이다.
- 주소 형식:

a.b.c.d/x
여기서 **x는 서브넷 부분의 비트 수**이다.

### 예시

이진 표현:
`11001000 00010111 00010000 00000000`
- 왼쪽부터 `/23`까지는 **subnet part**
- 나머지 비트는 **host part**

CIDR 표기:  
**200.23.16.0/23**

## 📌 요약

- CIDR은 기존 클래스 기반(Class A/B/C)의 고정 길이 네트워크 부분을 없애고,  
    **서브넷 길이를 원하는 만큼(x 비트) 지정할 수 있게 만든 방식**이다.    
- 주소는 **a.b.c.d/x** 형태로 표기되며, x는 **네트워크(bit) 구간의 길이**를 의미한다.
- 예: `/23` → 첫 23비트가 네트워크(subnet), 나머지 9비트가 호스트(host) 역할.


## 문제 번역

어떤 라우터가 세 개의 서브넷 **Subnet 1, Subnet 2, Subnet 3** 를 상호 연결하고 있다고 가정한다.  
세 서브넷의 모든 인터페이스는 **223.1.17/24** 프리픽스를 가져야 한다고 하자.

또한 다음과 같은 요구 사항이 있다.

- **Subnet 1**: 최대 **62개의 인터페이스**를 지원해야 함
- **Subnet 2**: 최대 **106개의 인터페이스**를 지원해야 함
- **Subnet 3**: 최대 **15개의 인터페이스**를 지원해야 함

이 조건을 만족하는, **a.b.c.d/x** 형태의 세 개의 네트워크 주소를 구하라.

## 풀이 과정

기본 네트워크: **223.1.17.0/24**  
→ 전체 주소 개수: 232−24=28=2562^{32-24} = 2^8 = 256232−24=28=256개

각 서브넷이 필요로 하는 **호스트(인터페이스) 수** 를 만족하려면  
서브넷당 usable host 수 =2h−2= 2^{h} - 2=2h−2 가 요구 개수 이상이 되어야 합니다.  
(여기서 hhh = 호스트 비트 수)

### 1) Subnet 1: 62개 필요

2h−2≥622^{h} - 2 \ge 622h−2≥62

- h=6h = 6h=6: 26−2=64−2=622^6 - 2 = 64 - 2 = 6226−2=64−2=62 → 정확히 만족  
    → 프리픽스 길이: 32−6=2632 - 6 = 2632−6=26  
    → **Subnet 1 → /26** 필요
    

### 2) Subnet 2: 106개 필요

2h−2≥1062^{h} - 2 \ge 1062h−2≥106

- h=6h = 6h=6: 64−2=62<10664 - 2 = 62 < 10664−2=62<106 (불충분)
    
- h=7h = 7h=7: 128−2=126≥106128 - 2 = 126 \ge 106128−2=126≥106 (충분)
    

→ 프리픽스 길이: 32−7=2532 - 7 = 2532−7=25  
→ **Subnet 2 → /25** 필요

### 3) Subnet 3: 15개 필요

2h−2≥152^{h} - 2 \ge 152h−2≥15

- h=4h = 4h=4: 16−2=14<1516 - 2 = 14 < 1516−2=14<15
    
- h=5h = 5h=5: 32−2=30≥1532 - 2 = 30 \ge 1532−2=30≥15


→ 프리픽스 길이: 32−5=2732 - 5 = 2732−5=27  
→ **Subnet 3 → /27** 필요

### 4) /24 안에서 주소 블록 배치

기본 네트워크 223.1.17.0/24 안에서, 큰 서브넷부터 차례로 할당합니다.

- **Subnet 2 (가장 큼, /25 = 128주소)**
    - 네트워크 주소: **223.1.17.0/25**
    - 사용 범위: 223.1.17.0 ~ 223.1.17.127

- **Subnet 1 (/26 = 64주소)**    
    - 다음 블록 시작: 223.1.17.128
    - 네트워크 주소: **223.1.17.128/26**
    - 사용 범위: 223.1.17.128 ~ 223.1.17.191

- **Subnet 3 (/27 = 32주소)**    
    - 다음 블록 시작: 223.1.17.192
    - 네트워크 주소: **223.1.17.192/27**
    - 사용 범위: 223.1.17.192 ~ 223.1.17.223


이렇게 하면 세 서브넷이 서로 겹치지 않고,  
각각 필요한 인터페이스 수를 모두 만족하며,  
모두 223.1.17.0/24 범위 안에 들어갑니다.

## 최종 답

조건을 만족하는 한 가지 예시는 다음과 같습니다.

- **Subnet 2**: `223.1.17.0/25` (최대 126 인터페이스)
- **Subnet 1**: `223.1.17.128/26` (최대 62 인터페이스)
- **Subnet 3**: `223.1.17.192/27` (최대 30 인터페이스)

문제는 단지 “조건을 만족하는 세 네트워크 주소”를 요구하므로,  
위와 같이 비겹치게만 나누면 정답이 됩니다.


## IP addresses: how to get one?

### 번역

IP 주소를 얻는 과정에는 사실 두 가지 질문이 존재합니다.

1. **호스트는** 자신의 네트워크 내부에서 **어떻게 IP 주소(주소의 host 부분)를 부여받는가?**
2. **네트워크는** 스스로를 식별하기 위한 **IP 주소(주소의 network 부분)를 어떻게 부여받는가?**

### 호스트는 어떻게 IP 주소를 얻는가?

- 시스템 관리자가 설정 파일(예: UNIX의 `/etc/rc.config`)에 **정적으로 직접 설정하는 방식**
- **DHCP(Dynamic Host Configuration Protocol)**
    - 서버로부터 IP 주소를 **동적으로 할당**받는 방식
    - “plug-and-play”가 가능함

## 요약

- IP 주소 획득에는 **호스트 단의 주소 할당**과 **네트워크 단의 주소 할당**이라는 두 관점이 존재함. 
- 호스트는 **정적 설정** 또는 **DHCP를 통한 동적 할당** 방식으로 IP 주소를 부여받음.


## DHCP: Dynamic Host Configuration Protocol

### 목표

DHCP의 목표는 호스트가 네트워크에 “가입(join)”할 때 **네트워크 서버로부터 IP 주소를 동적으로 부여받도록 하는 것**입니다.

- 사용 중인 주소에 대해 **임대 기간(lease)을 갱신**할 수 있음
- 주소의 **재사용이 가능함**(연결되어 있는 동안에만 주소를 보유)
- 네트워크에 접속하거나 떠나는 **모바일 사용자에게 유용함**

### DHCP 동작 개요

- 호스트가 **DHCP discover** 메시지를 브로드캐스트함 _(선택적)_    
- DHCP 서버가 **DHCP offer** 메시지로 응답함 _(선택적)_
- 호스트가 **DHCP request** 메시지를 보내 주소를 요청함
- DHCP 서버가 **DHCP ack** 메시지를 보내 주소를 최종적으로 할당함

## 요약

DHCP는 호스트가 네트워크에 접속할 때 IP 주소를 자동으로 부여하는 프로토콜이며, discover → offer → request → ack의 순서로 주소가 할당된다.


## DHCP client–server scenario

일반적으로 DHCP 서버는 **라우터 내부에 함께 배치(co-located)**되어 있으며, 라우터가 연결된 **모든 서브넷(subnet)**에 대해 주소 할당 서비스를 제공합니다.

네트워크에 새로 도착한 **DHCP 클라이언트는** 이 네트워크에서 사용할 **IP 주소가 필요**합니다.

그림에서는 여러 서브넷(223.1.1.x, 223.1.2.x, 223.1.3.x)이 라우터에 연결되어 있으며, DHCP 서버(223.1.2.5)가 이 모든 서브넷에 걸쳐 IP 주소를 할당하는 구조를 보여줍니다.

## 요약

- DHCP 서버는 보통 **라우터 안에 포함**되어 여러 서브넷을 동시에 관리함.    
- 새로 접속하는 장치는 DHCP 클라이언트로서 **IP 주소 할당**을 요청함.
- 하나의 DHCP 서버가 라우터를 통해 여러 네트워크 대역에 주소를 제공할 수 있음.


